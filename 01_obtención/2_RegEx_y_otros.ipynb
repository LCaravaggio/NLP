{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_RegEx y otros.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNhYeXk7E2ugcFciVgu7jeK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/NLP/blob/main/01_obtenci%C3%B3n/2_RegEx_y_otros.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMkwF9FETyec"
      },
      "source": [
        "# Expresiones Regulares\n",
        "### Identificación de patrones\n",
        "#####  \".\" : Matchea cualquier caracter excepto '\\n'\n",
        "#####  \"^\" y  \"$\": Matchean el comienzo y el final de un string\n",
        "##### \"[]\": Matchea el set de caracteres que se encuentren dentro de los corchetes (r\"l[ao]s\" machea \"las\" y \"los\")\n",
        "##### \\d: Matchea digitos; equivalente a [0-9].\n",
        "##### \\D: Matchea caracteres que NO sean digitos; equivalente a [^0-9].\n",
        "##### \\s: Matchea espacios en blanco; equivalente a [ \\t\\n\\r\\f\\v].\n",
        "##### \\S: Matchea espacios que NO esten en blanco; equivalente a [^ \\t\\n\\r\\f\\v].\n",
        "##### \\w: Matchea caracteres alfanuméricos; equivalente a [a-zA-Z0-9_].\n",
        "##### \\W: Matchea caracteres que NO sean alfanuméricos; equivalente a[^a-zA-Z0-9_].\n",
        "##### a|b: Matchea \"a\" o \"b\"\n",
        "##### Repeticiones:\n",
        "##### \"+\": Matchea 1 o mas ocurrencias\n",
        "##### \"*\": Matchea 0 o mas ocurrencias\n",
        "##### \"?\": Matchea 0 o 1 ocurrencia\n",
        "##### \"{n, m}\": Matchea entre n y m ocurrencias\n",
        "##### \"\\\\\": Permite matchear caracteres especiales\n",
        "##### para más info ver: https://docs.python.org/3.1/library/re.html#re-syntax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab1mrdcVwrrA"
      },
      "outputs": [],
      "source": [
        "import re # Librería para trabajar con expresiones regulares\n",
        "import pandas as pd # Librería para trabajar con DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxKkd__WwrrD"
      },
      "outputs": [],
      "source": [
        "texto = \"\"\"(Jefe de los Minisupers) 14'49'' Podéis hacerme tres preguntas.\n",
        "(Apu) 14'58'' Qué bueno, porque sólo necesito una.\n",
        "(Homer) 15'05'' ¿Usted es el Jefe de los Minisupers?\n",
        "(Jefe de los Minisupers) 15'13'' Así es.\n",
        "(Homer) 15'22'' ¿Usted?\n",
        "(Jefe de los Minisupers) 15'38'' Así es.\n",
        "(Homer) 15'41'' ¿Está seguro?\n",
        "(Jefe de los Minisupers) 16' Sí. Espero que los haya iluminado.\n",
        "(Apu) 16'11'' Pero tengo que...\n",
        "(Jefe de los Minisupers) 16'2'' Gracias. Vuelva pronto.\n",
        "(Apu) 16'29'' Pero.\n",
        "(Jefe de los Minisupers) 16'33'' Graciaaaaas. Vuelva pronto.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEZ-8_Q9wrrF"
      },
      "outputs": [],
      "source": [
        "print(texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5hB4eSOwrrG"
      },
      "outputs": [],
      "source": [
        "# re.search() busca el patron de la expresion regular y devuelve un objeto si lo encuentra\n",
        "match = re.search(r\"Gracias. Vuelva pronto\", texto)\n",
        "match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NunFZQ2wrrJ"
      },
      "outputs": [],
      "source": [
        "# el \"if\" testea si re.search() encontró el patrón; \n",
        "# match.group() devuelve el primer matcheo \n",
        "# match.span() el rango de sus indices\n",
        "if match:\n",
        "    print(\"El primer matcheo es:\",match.group())\n",
        "    print(\"El rango de los indices es:\",match.span())\n",
        "else: \n",
        "    print(\"El patron NO esta en el texto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiuhW_XNwrrL"
      },
      "outputs": [],
      "source": [
        "# re.findall() devuelve todos los matcheos\n",
        "re.findall(r\"Gracia+s\\. Vuelva pronto\", texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gqg8vHIvwrrP"
      },
      "outputs": [],
      "source": [
        "# re.findall() devuelve todos los matcheos\n",
        "re.findall(r\"\\d\\d'\\d\\d''\", texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXtBg2ZpwrrS"
      },
      "outputs": [],
      "source": [
        "# re.findall() devuelve todos los matcheos\n",
        "re.findall(r\"\\d\\d'\\d{0,2}'{0,2}\", texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQbQwB1JwrrT"
      },
      "outputs": [],
      "source": [
        "re.findall(r\"\\(.*\\)\", texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IuVBzLJwrrW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0_MIh4AwrrX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYJUQb8Fwrrc"
      },
      "source": [
        "### Grupos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA-ub8wywrrc"
      },
      "outputs": [],
      "source": [
        "# Los paréntesis definen los grupos, que identifican los elementos a devolver\n",
        "re.findall(r\"\\((.*)\\)\", texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYO_m-dBwrrg"
      },
      "outputs": [],
      "source": [
        "script = re.findall(r\"\\((.*)\\) (\\d\\d'\\d{0,2}'{0,2}) (.*)\", texto)\n",
        "script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMbwxvu3wrri"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(script) # Dataframe de pandas\n",
        "df.columns = [\"personaje\",\"tiempo\",\"texto\"]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVi9z5g8wrrk"
      },
      "outputs": [],
      "source": [
        "df[df[\"personaje\"] == \"Jefe de los Minisupers\"] # Pandas continuará..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xp-0F_CZwrrm"
      },
      "outputs": [],
      "source": [
        "# re.finditer(pattern, string) devuelve un iterador de MatchObjects\n",
        "script_iterator = re.finditer(r\"\\((.*)\\) (\\d\\d'\\d{0,2}'{0,2}) (.*)\", texto)\n",
        "scripts = []\n",
        "for match in script_iterator:\n",
        "    g1 = match.group(1)\n",
        "    g2_min = match.group(2).split(\"'\")[0] #  \"16'33''\".split(\"'\") -> ['16', '33', '', '']\n",
        "    g2_seg = match.group(2).split(\"'\")[1]\n",
        "    g3 = match.group(3)\n",
        "    span = match.span()\n",
        "    scripts.append([g1,g2_min,g2_seg,g3,span])\n",
        "\n",
        "scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk39__V1wrrn"
      },
      "outputs": [],
      "source": [
        "df_scripts = pd.DataFrame(scripts)\n",
        "df_scripts.columns = [\"personaje\",\"min\",\"seg\",\"texto\",\"indices\"]\n",
        "df_scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fjk88gdwrrp"
      },
      "source": [
        "### Más sobre grupos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G555Edqhwrrq"
      },
      "source": [
        "#### Hallar el hablante y los tiempos en los que habla.  Pero solo para Homero o Apu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbm-Z4iSwrrr"
      },
      "outputs": [],
      "source": [
        "# (?:...) No identifica el contenido del parentesis con un grupo\n",
        "re.findall(r\"\\((?:Homer|Apu)\\) \\d\\d'\\d{0,2}'{0,2}\",texto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xlA1qD-wrru"
      },
      "source": [
        "#### Cambiar \"(Personaje)\" por \"Personaje:\" en el texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUwTf9eNwrru"
      },
      "outputs": [],
      "source": [
        "re.sub(r\"\\((.*)\\)\",\"\\g<1>:\",texto)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOtBl8CKwrrw"
      },
      "source": [
        "#### Cambiar el texto precedido por \"Jefe de los Minisupers:\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CngUQq8ywrrw"
      },
      "outputs": [],
      "source": [
        "# machea si es precedido por un match de (?<=...)\n",
        "print(re.sub(r\"(?<=Jefe de los Minisupers:).*\",\" PALABRAS SANTAS\",texto))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3w7DDJvwrry"
      },
      "source": [
        "### Greedy vs Non Greedy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjDYEde5lAW_"
      },
      "outputs": [],
      "source": [
        "textos = \" \".join(df_scripts[\"texto\"])\n",
        "textos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vn51UIUwrr0"
      },
      "outputs": [],
      "source": [
        "# quiero extraer todas las preguntas\n",
        "re.findall(r\"\\¿.*\\?\",textos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_YwfQpqwrr2"
      },
      "source": [
        "###  + y \\* machean el patron mas largo posible ( se dice que +  y \\* son \"greedy\")\n",
        "### para que sean non-greedy se le agrega un \"?\" a la derecha => \"*?\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQfSc9sDwrr3"
      },
      "outputs": [],
      "source": [
        "# quiero extraer todas las preguntas\n",
        "re.findall(r\"\\¿.*?\\?\",textos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrKd5Qoqwrr5"
      },
      "source": [
        "# Preprocesamiento de Textos: Normalización "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQXGtZWIloTn"
      },
      "outputs": [],
      "source": [
        "print(texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc19S_UOwrr5"
      },
      "outputs": [],
      "source": [
        "# re.sub(patron, remplazo, string)\n",
        "# devuelve el string con el patron reemplazado \n",
        "textos = re.sub(r\"a+\",\"a\",texto)\n",
        "print(textos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPsBL3nzwrr7"
      },
      "source": [
        "# Tokenización\n",
        "### tokenizar es segmentar el texto en unidades (tokens) \n",
        "### los tokens podrían ser palabras, numeros, signos de puntuacion, emoticones, etc..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzfzkzOGwrr7"
      },
      "source": [
        "### En este ejemplo buscamos calcular la frecuencia de aparicion de las palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdxcI1CIwrr8"
      },
      "outputs": [],
      "source": [
        "tokens = re.split(r\"\\W+\",textos)\n",
        "print(\"hay\",len(tokens),\"tokens\")\n",
        "tokens[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02axuOY2wrr9"
      },
      "outputs": [],
      "source": [
        "pd.Series(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H54-sktqwrr_"
      },
      "outputs": [],
      "source": [
        "pd.Series(tokens).value_counts().head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlcStgslwrsA"
      },
      "source": [
        "### Tokenización de oraciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ERmOGv9wrsB"
      },
      "outputs": [],
      "source": [
        "dificil_de_tokenizar = \"Dr. formulate it to me. I don't know how to tokenize this! it's impossible!\"\n",
        "re.split(\"[\\.!]\",dificil_de_tokenizar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx52iPvXwrsC"
      },
      "source": [
        "## NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbi1e3mwmSNB"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzK-LPr5wrsC"
      },
      "outputs": [],
      "source": [
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2sk0ghnwrsE"
      },
      "outputs": [],
      "source": [
        "sent = sent_tokenize(dificil_de_tokenizar)\n",
        "sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_tjaiTTwrsG"
      },
      "outputs": [],
      "source": [
        "word_tokenize(sent[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAkpCTajwrsH"
      },
      "source": [
        "### Ahora en español"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS2svQ32wrsI"
      },
      "outputs": [],
      "source": [
        "sents = sent_tokenize(texto,language=\"spanish\")\n",
        "sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UJdbAWSwrsJ"
      },
      "outputs": [],
      "source": [
        "tokens = word_tokenize(textos,language=\"spanish\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZkX-MS6wrsK"
      },
      "outputs": [],
      "source": [
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q871gc_uwrsM"
      },
      "source": [
        "### los problemas con el \"¿\" lo podemos emparchar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZ14MUo7wrsM"
      },
      "outputs": [],
      "source": [
        "textos_retocados = re.sub(r\"¿\",\" ¿ \",textos)\n",
        "tokens = word_tokenize(textos_retocados,language=\"spanish\")\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QLLT4iJwrsP"
      },
      "outputs": [],
      "source": [
        "palabras = [token.lower() for token in tokens if token.isalpha()]\n",
        "palabras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvuwxxDxwrsR"
      },
      "source": [
        "### Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TtPgPJuOs38"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrVwIRRrwrsR"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stoplist = stopwords.words(\"spanish\")\n",
        "stoplist[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6fByQsowrsV"
      },
      "outputs": [],
      "source": [
        "# elimino los stopwords\n",
        "palabras = [token.lower() for token in tokens if token.lower() not in stoplist and token.isalpha()]\n",
        "palabras[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgTX8XKzwrsY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roFjWSKgH_ii"
      },
      "source": [
        "## Ejercicio 1\n",
        "### armar un texto que tenga sentido usando las variables a, b, c y d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViCz2clGIDBX"
      },
      "outputs": [],
      "source": [
        "a = \"xxxxxxxxxxxxxxxx veces \"  \n",
        "b = 1000 \n",
        "c = \"xxxno puedo soñar xxxxx\" \n",
        "d = \"xlxaxsx xmxixsxmxaxsx xcxoxsxaxs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z-5EbssJlMf"
      },
      "source": [
        "## Ejercicio 2: \n",
        "### a) cuantas letras hay en la tercer oración?\n",
        "### b) cuantas palabras hay en todo el texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOJahA_gJmjd"
      },
      "outputs": [],
      "source": [
        "texto_ej2 = \"Citadme diciendo que me han citado mal. Claro que lo entiendo. Incluso un niño de cinco años podría entenderlo. ¡Que me traigan un niño de cinco años!\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kyl3FBMMQ-1"
      },
      "source": [
        "##  Ejercicio 3\n",
        "### Amar un Regex para extraer todas las fechas mencionadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yky1OMbmKxvv"
      },
      "outputs": [],
      "source": [
        "texto_ej3=\"compras de julio: el 02/07 yerba, 5/7/18 azucar y 8/7 cafe. Agosto: 02-08-2018, 15-8-2018 y 29-08 mas yerba \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0xAmIgcwrsa"
      },
      "source": [
        "## Ejercicio 4\n",
        "\n",
        "### a) Cuales son las 10 palabras mas frecuentes? no contar efecto de si es mayúscula o minúscula. \n",
        "### b) Cuantas palabras son stopwords? que porcentaje de las palabras son stopwords?\n",
        "### c) Sacar las tíldes (normalización)\n",
        "### d) Pasar los millones a números 1.800 millones -> 1.800.000  (normalización)\n",
        "### e) Extraer los numeros asociados a dolares, pesos y porcentajes\n",
        "### f) Plotear en eje log-log un la frequencia de las palabras vs su ranking: es decir representar en un scatterplot cuantas veces aparece la palabra mas frecuente (ranking=1), cuantas veces la 2da mas frecuentes (ranking=2)..., la n-esima mas frecuente (ranking = n) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j8vQmOewrsc"
      },
      "outputs": [],
      "source": [
        "texto_ej4='Jueves 29.3.2018 BUENOS AIRES\\n INGRESAR EDICIÓN IMPRESA Suscribirse Onmail\\n   SEGUINOS\\nPORTADA\\t\\tPOLÍTICA\\tMUNDO\\tNACIONAL\\t\\tINFO. GRAL\\t\\tESPECTÁCULOS\\t\\t\\n\\nambito.comJueves 29.3.2018\\n\\nECONOMÍA\\n\\n\\n\\n\\n\\nPOR MARIANA LEIVA.- lunes 26 de Marzo de 2018\\nEl BCRA intervino por séptima rueda consecutiva y el dólar cedió cinco centavos a $ 20,49\\nMariana Leiva \\t\\nMARIANA LEIVA\\n \\nCon un Banco Central presente en la rueda por séptima rueda consecutiva, el dólar inició la semana con nueva baja, al ceder cinco centavos a $ 20,49 en agencias y bancos de la city porteña, de acuerdo al promedio de ámbito.com. \\n\\nEl billete -que anotó su segunda caída consecutiva- se desacopló del segmento mayorista, donde la divisa terminó sin cambios a $ 20,21.\\n\\nDurante la rueda, la moneda estadounidense tuvo un recorrido muy acotado en una rueda en la que el Banco Central volvió a fijar límites al movimiento de los precios. Operadores estimaron que la autoridad monetaria habría vendido unos u$s 100 millones, con lo que en el mes llevaría desembolsado cerca de u$s 1.800 millones. \\n\\nA poco de iniciada la sesión se hizo presente una postura de venta en $ 20,21 efectivizada por el BCRA que señaló el límite superior fijado en la banda de fluctuación del tipo de cambio. La presencia oficial, en este sentido, disuadió desde el arranque presiones sobre los precios que merced a una mayor oferta privada descendieron hasta tocar mínimos en los $ 20,163. Al final del día, sus ventas sumaron u$s 69 millones.\\n\\nLa oferta provino, además, de las liquidaciones de exportadores cerealeros con un promedio u$s 85 millones por día (aumentó 40% que la semana anterior) y también de otros rubros que realimentan la venta de la divisa norteamericana, además de algunos inversores tentados por la tasa de interés en pesos ahora que tienen un dólar con poca oscilación y con un techo de $ 20,4 y un piso de $ 20,2, según puntualizaron de ABC Mercado de Cambios. \\n\\nDesde PR Corredores de Cambio, indicaron que \"el inicio de la semana corta presentó un escenario dominado en forma reiterada por la regulación oficial del tipo de cambio. La estrategia del Banco Central apuntó a dejar sin posibilidad de que los precios del dólar superaran el nivel alcanzado en el cierre de la semana pasada pero sin forzar una nueva caída en su cotización\". El volumen operado descendió un 6,5% a u$s 758 millones.\\n\\n\"La suerte de la evolución del dólar en el cierre de marzo parece estar echada y, dadas las características de las últimas regulaciones oficiales su nivel para el miércoles próximo se anticipa que no estará muy alejado del alcanzado en la fecha, un dato que los mercados de futuros descuentan en su cotización de esta rueda\", agregaron.\\n\\nEn el mercado de dinero entre bancos, el \"call money\" operó estable a un promedio del 25,5% TNA y en \"swaps\" cambiarios se pactaron u$s 148 millones para tomar y/o colocar fondos en pesos mediante el uso de compra-venta de dólares para el martes y el miércoles. Las Lebac en el circuito secundario se operaban al plazo de 23 días a 23,55% TNA, y la de 268 días al 24,9% TNA.\\n\\nEn el Rofex, donde se operaron u$s 1.156 millones, más del 40% se operó para fin de mes a $ 20,215 con una tasa implícita del 9% TNA y el plazo más largo fue julio a $ 21,63 a una tasa del 20,50% TNA. \\n\\nEn la plaza paralela, el blue cayó seis centavos a $ 20,88, según el relevamiento de este medio en cuevas del microcentro porteño. Asimismo, el \"contado con liqui\" bajó 10 centavos a $ 20,19.\\n\\nPor último, las reservas del Banco Central aumentaron este lunes u$s 18 millones, hasta los u$s 60.917 millones.\\nTAGS\\n \\n\\n\\n\\n'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0oY_qnbSXDY"
      },
      "outputs": [],
      "source": [
        "print(texto_ej4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj-Rl4lFIia2"
      },
      "source": [
        "## Ejemplo de respuesta ej 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3YecRXPwrsp"
      },
      "outputs": [],
      "source": [
        "c[3:-5]+str(b)+a[-7:]+d[1::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NPC7G-zwrsr"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KIea6nIKFwm"
      },
      "source": [
        "## Ejemplo de respuesta ej 2\n",
        "### a) cuantas letras hay en la tercer oración?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPVptgJaKJQB"
      },
      "outputs": [],
      "source": [
        "texto_ej2.split(\".\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7KxZgx4KVup"
      },
      "outputs": [],
      "source": [
        "len(texto_ej2.split(\".\")[2].replace(\" \",\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIdBtGzyLv_u"
      },
      "source": [
        "### b) cuantas palabras hay en todo el texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ik8yEQL4Lll8"
      },
      "outputs": [],
      "source": [
        "len(texto_ej2.split(\" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g41zAcSqsS6v"
      },
      "source": [
        "## Ejemplo de respuesta ej 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7FfSZOosQo8"
      },
      "outputs": [],
      "source": [
        "re.findall(r\"\\d{1,2}[/-]\\d{1,2}[/-]?\\d{0,4}\",texto_ej3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CXsQruAwrss"
      },
      "source": [
        "## Ejemplo de respuesta ej 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krigxOSQwrss"
      },
      "source": [
        "### a) Cuales son las 10 palabras mas frecuentes? no contar efecto de si es mayúscula o minúscula. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANHz-N-Xwrst"
      },
      "outputs": [],
      "source": [
        "palabras_frec = pd.Series([w for w in word_tokenize(texto_ej4.lower(),language=\"spanish\") if w.isalpha()]).value_counts()  \n",
        "palabras_frec[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F65Yqk4uwrsu"
      },
      "source": [
        "### b) cuantas palabras son stopwords? que porcentaje de las palabras son stopwords?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6JwnfU5wrsu"
      },
      "outputs": [],
      "source": [
        "palabras = [w for w in word_tokenize(texto_ej4.lower(),language=\"spanish\") if w.isalpha()]\n",
        "texto_ej4_stopwords = [w for w in palabras if w in stoplist]\n",
        "n_stopwords = len(texto_ej4_stopwords)\n",
        "print(\"hay\",n_stopwords,\"stopwords\")\n",
        "porcentaje = n_stopwords/len(palabras)*100\n",
        "print(\"un %\",round(porcentaje),\"de las palabras son stopwords! WTF\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu7dwpfuwrsw"
      },
      "outputs": [],
      "source": [
        "# usando pandas\n",
        "print( palabras_frec[[p in stoplist for p in palabras_frec.index]].sum())\n",
        "print( palabras_frec[[p in stoplist for p in palabras_frec.index]].sum() /palabras_frec.sum() *100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_UqVHmiwrsy"
      },
      "source": [
        "### c) Sacar las tíldes (normalización)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ISSDUR4wrsy"
      },
      "outputs": [],
      "source": [
        "def sacar_tildes(texto):\n",
        "    texto = re.sub(\"á\",\"a\",texto)\n",
        "    texto = re.sub(\"é\",\"e\",texto)\n",
        "    texto = re.sub(\"í\",\"i\",texto)\n",
        "    texto = re.sub(\"ó\",\"o\",texto)\n",
        "    texto = re.sub(\"ú\",\"u\",texto)\n",
        "    texto = re.sub(\"Á\",\"A\",texto)\n",
        "    texto = re.sub(\"É\",\"E\",texto)\n",
        "    texto = re.sub(\"Í\",\"I\",texto)\n",
        "    texto = re.sub(\"Ó\",\"O\",texto)\n",
        "    return re.sub(\"Ú\",\"U\",texto)\n",
        "     \n",
        "texto_ej4c = sacar_tildes(texto_ej4)\n",
        "print(texto_ej4c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyOxgjKawrsz"
      },
      "source": [
        "### d) pasar los millones a números 1.800 millones -> 1.800.000  (normalización)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVEHYsAIwrsz"
      },
      "outputs": [],
      "source": [
        "texto_ej4d = re.sub(r\"(\\d) millones\",\"\\g<1>.000.000\",texto_ej4)\n",
        "print(texto_ej4d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMNs9g-Twrs1"
      },
      "source": [
        "### e) extraer los numeros asociados a dolares, pesos y porcentajes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rGrEmX_wrs1"
      },
      "outputs": [],
      "source": [
        "print(\"Dolares:\",re.findall(r\"(?<=u\\$s )\\d+(?:\\.\\d\\d\\d)*(?:\\,\\d+)?\",texto_ej4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPZL_pPdwrs3"
      },
      "outputs": [],
      "source": [
        "print(\"Pesos:\",re.findall(r\"(?<=\\$ )\\d+(?:\\.\\d\\d\\d)*(?:\\,\\d+)?\",texto_ej4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGg0kN9ywrs4"
      },
      "outputs": [],
      "source": [
        "print(\"Porcentajes:\",re.findall(r\"\\d+(?:\\,\\d+)?(?=\\%)\",texto_ej4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHR_rapbwrs5"
      },
      "source": [
        "### f) Plotear en eje log-log un la frequencia de las palabras vs su ranking: es decir representar en un scatterplot cuantas veces aparece la palabra mas frecuente (ranking=1), cuantas veces la 2da mas frecuentes (ranking=2)..., la n-esima mas frecuente (ranking = n) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVTVZ-USwrs5"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(range(1,len(palabras_frec)+1),palabras_frec)\n",
        "plt.xscale(\"log\");plt.yscale(\"log\")\n",
        "plt.xlabel(\"Ranking\"); plt.ylabel(\"Frecuencia\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tggu6bHlwrs6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}