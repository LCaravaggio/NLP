{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/NLP/blob/main/08_LanguageModels/NeuralLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a entrenar un modelo de lenguaje neuronal feed-forward basado en una ventana de contexto fija y embeddings estáticos. Como datos de entrenamiento, vamos a usar recetas de cocina en español."
      ],
      "metadata": {
        "id": "DwU_koArH8JW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuración del entorno"
      ],
      "metadata": {
        "id": "q2xVhaQ46Wyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU datasets spacy watermark"
      ],
      "metadata": {
        "id": "3cHmzFdYbDTm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "id": "dDUxxsDNLkN2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext watermark"
      ],
      "metadata": {
        "id": "Xv815WnZBI41"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%watermark -vmp datasets,spacy,torch,numpy,pandas,tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmbjr89RBKpR",
        "outputId": "3493d7c0-5435-4ae3-fed9-1a5a338fe191"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "datasets: 3.0.0\n",
            "spacy   : 3.7.6\n",
            "torch   : 2.4.1+cu121\n",
            "numpy   : 1.26.4\n",
            "pandas  : 2.1.4\n",
            "tqdm    : 4.66.5\n",
            "\n",
            "Compiler    : GCC 11.4.0\n",
            "OS          : Linux\n",
            "Release     : 6.1.85+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para usar GPU, arriba a la derecha seleccionar \"Change runtime type\" --> \"T4 GPU\".\n",
        "\n",
        "Es un buena idea desarrollar con CPU, y usar GPU para la corrida final, para que Google no nos limite el uso. En esta notebook puede ser útil usar GPU."
      ],
      "metadata": {
        "id": "Hts4XQ9L9ptO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QknGEM69eO1",
        "outputId": "bf2af6dd-a5fe-43cc-9e44-b4f00642bca5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "Vamos a usar un [corpus de recetas de SomosNLP](https://huggingface.co/datasets/somosnlp/RecetasDeLaAbuela)."
      ],
      "metadata": {
        "id": "pN9ZrHk5h6mL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"somosnlp/RecetasDeLaAbuela\", \"version_1\")"
      ],
      "metadata": {
        "id": "gzVdx6xVh6Sj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a08189-751d-447a-dd2d-473517216856"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vemos la estructura:\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMpZStLajfTu",
        "outputId": "b55ab274-ab0a-419a-f911-908fac2fdf48"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Id', 'Nombre', 'URL', 'Ingredientes', 'Pasos', 'Pais', 'Duracion', 'Categoria', 'Contexto', 'Valoracion y Votos', 'Comensales', 'Tiempo', 'Dificultad', 'Valor nutricional'],\n",
            "        num_rows: 20236\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conservamos pais = \"ESP\":\n",
        "dataset = dataset.filter(lambda x: x[\"Pais\"] == \"ESP\")"
      ],
      "metadata": {
        "id": "gsyy4VwxApuf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vemos un ejemplo al azar:\n",
        "dataset[\"train\"][300]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alRfTgMcjnez",
        "outputId": "14719445-3c09-4286-de27-28d5d15be15e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Id': 1701,\n",
              " 'Nombre': 'croquetas de pollo asado',\n",
              " 'URL': 'https://www.recetasgratis.net/receta-de-croquetas-de-pollo-asado-59330.html',\n",
              " 'Ingredientes': \"['500 gramos de Pollo', '1 unidad de Cebolla', '300 mililitros de Aceite de oliva', '600 mililitros de Leche                                                                    (2½ tazas)', '2 cucharadas soperas de Harina', '1 pizca de Sal', '1 pizca de Nuez moscada molida', '1 pizca de Pimienta negra molida', '1 unidad de Huevo', '200 gramos de Pan rallado']\",\n",
              " 'Pasos': \"['1 Reunimos todos los ingredientes para preparar las croquetas de pollo asado.', '2 Colocamos el pollo sin piel en una fuente para horno, salpimentamos, echamos un poco de aceite de oliva y lo metemos al horno a 180 ºC durante 25 minutos.También podéis hacer esta receta de croquetas de pollo asado si os ha sobrado carne de haber preparado, por ejemplo, pollo al horno con patatas y cebolla.', '3 Picamos la cebolla de forma fina y la salteamos en la sartén con un poco de aceite de oliva. Dejamos que se cocine durante 3 minutos.', '4 Una vez cocido, desmenuzamos el pollo, quitamos los huesos y lo agregamos al sofrito de cebolla. Ponemos un poco de sal y pimienta, y dejamos que se cocine durante 3 minutos.', '5 Agregamos la harina, dejamos que se cocine durante 2 minutos, y añadimos la leche poco a poco hasta que la masa de las croquetas de pollo espese.Ponemos un poco de sal, pimienta y nuez moscada molida. Sin dejar de remover la masa, dejamos cocinar hasta que ésta no se pegue en la sartén (aproximadamente 15 minutos). Truco: Si la masa queda muy líquida se puede añadir más harina y viceversa.', '6 Una vez formada la masa de las croquetas de pollo asado, dejamos que se enfríe un poco, y formamos las croquetas con ayuda de 2 cucharas, o con las manos.', '7 Rebozamos las croquetas de pollo asado con huevo batido y pan rallado, y las freímos en abundante aceite caliente hasta que queden doradas. Una vez fritas, las colocamos sobre papel de cocina para eliminar el exceso de aceite.', '8 Estas croquetas de pollo asado se pueden preparar como entrantes, junto con otros aperitivos como las brochetas de pescado y langostinos o los crepes salados de salmón.']\",\n",
              " 'Pais': 'ESP',\n",
              " 'Duracion': '01:00',\n",
              " 'Categoria': \"['Recetas españolas']\",\n",
              " 'Contexto': '¡Cómo nos gustan las croquetas caseras! Si no sabes qué hacer con pollo asado que te ha sobrado, apunta los consejos que te damos en RecetasGratis.net para no tirar nada.Para aprovechar sobras de pollo puedes hacer esta receta de croquetas con pollo asado fácil que te vamos a explicar paso a paso para que no te pierdas y te queden riquísimas.Para aprender cómo hacer croquetas solo tienes que poner atención a la masa para que te quede esponjosa y cremosa. Nosotros te lo contamos en el paso a paso de estas croquetas de pollo asado. ¡No te la pierdas!',\n",
              " 'Valoracion y Votos': None,\n",
              " 'Comensales': '4 comensales',\n",
              " 'Tiempo': 'Entrante',\n",
              " 'Dificultad': 'Dificultad media',\n",
              " 'Valor nutricional': 'Bajo en calorías, Sin grasa, Alto en grasas reducidas'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A veces los textos son listas no parseadas como tales.\n",
        "# En tal caso, hacemos un join de la lista.\n",
        "import re\n",
        "\n",
        "def preprocess(example):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    if example[\"Pasos\"].startswith(\"[\"):\n",
        "        pasos_list = eval(example[\"Pasos\"].encode('unicode_escape'))\n",
        "        example[\"Pasos\"] = \" \".join(pasos_list)\n",
        "    # Eliminamos whitespace duplicado:\n",
        "    example[\"Pasos\"] = re.sub(r'\\s+', ' ', example[\"Pasos\"])\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(preprocess)"
      ],
      "metadata": {
        "id": "my5Jr-FHARC4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][300]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abSposkFCH7r",
        "outputId": "4f17fb2c-1ff7-4b72-bfcf-84f8fe924fc0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Id': 1701,\n",
              " 'Nombre': 'croquetas de pollo asado',\n",
              " 'URL': 'https://www.recetasgratis.net/receta-de-croquetas-de-pollo-asado-59330.html',\n",
              " 'Ingredientes': \"['500 gramos de Pollo', '1 unidad de Cebolla', '300 mililitros de Aceite de oliva', '600 mililitros de Leche                                                                    (2½ tazas)', '2 cucharadas soperas de Harina', '1 pizca de Sal', '1 pizca de Nuez moscada molida', '1 pizca de Pimienta negra molida', '1 unidad de Huevo', '200 gramos de Pan rallado']\",\n",
              " 'Pasos': '1 Reunimos todos los ingredientes para preparar las croquetas de pollo asado. 2 Colocamos el pollo sin piel en una fuente para horno, salpimentamos, echamos un poco de aceite de oliva y lo metemos al horno a 180 ºC durante 25 minutos.También podéis hacer esta receta de croquetas de pollo asado si os ha sobrado carne de haber preparado, por ejemplo, pollo al horno con patatas y cebolla. 3 Picamos la cebolla de forma fina y la salteamos en la sartén con un poco de aceite de oliva. Dejamos que se cocine durante 3 minutos. 4 Una vez cocido, desmenuzamos el pollo, quitamos los huesos y lo agregamos al sofrito de cebolla. Ponemos un poco de sal y pimienta, y dejamos que se cocine durante 3 minutos. 5 Agregamos la harina, dejamos que se cocine durante 2 minutos, y añadimos la leche poco a poco hasta que la masa de las croquetas de pollo espese.Ponemos un poco de sal, pimienta y nuez moscada molida. Sin dejar de remover la masa, dejamos cocinar hasta que ésta no se pegue en la sartén (aproximadamente 15 minutos). Truco: Si la masa queda muy líquida se puede añadir más harina y viceversa. 6 Una vez formada la masa de las croquetas de pollo asado, dejamos que se enfríe un poco, y formamos las croquetas con ayuda de 2 cucharas, o con las manos. 7 Rebozamos las croquetas de pollo asado con huevo batido y pan rallado, y las freímos en abundante aceite caliente hasta que queden doradas. Una vez fritas, las colocamos sobre papel de cocina para eliminar el exceso de aceite. 8 Estas croquetas de pollo asado se pueden preparar como entrantes, junto con otros aperitivos como las brochetas de pescado y langostinos o los crepes salados de salmón.',\n",
              " 'Pais': 'ESP',\n",
              " 'Duracion': '01:00',\n",
              " 'Categoria': \"['Recetas españolas']\",\n",
              " 'Contexto': '¡Cómo nos gustan las croquetas caseras! Si no sabes qué hacer con pollo asado que te ha sobrado, apunta los consejos que te damos en RecetasGratis.net para no tirar nada.Para aprovechar sobras de pollo puedes hacer esta receta de croquetas con pollo asado fácil que te vamos a explicar paso a paso para que no te pierdas y te queden riquísimas.Para aprender cómo hacer croquetas solo tienes que poner atención a la masa para que te quede esponjosa y cremosa. Nosotros te lo contamos en el paso a paso de estas croquetas de pollo asado. ¡No te la pierdas!',\n",
              " 'Valoracion y Votos': None,\n",
              " 'Comensales': '4 comensales',\n",
              " 'Tiempo': 'Entrante',\n",
              " 'Dificultad': 'Dificultad media',\n",
              " 'Valor nutricional': 'Bajo en calorías, Sin grasa, Alto en grasas reducidas'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos un partición train/test y achicamos (solo para trabajar mas rapido). Y conservamos solo el texto de las recetas."
      ],
      "metadata": {
        "id": "uhD4vWA9-24O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle(seed=33)"
      ],
      "metadata": {
        "id": "7jv8x2Kb-7ew"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts_train = dataset[\"train\"].select(range(0, 4_000))[\"Pasos\"]\n",
        "texts_test = dataset[\"train\"].select(range(4_000, 8_000))[\"Pasos\"]"
      ],
      "metadata": {
        "id": "Z7rgvwpCrY_e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "print(textwrap.fill(texts_train[33], 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-jz484l2gYV",
        "outputId": "e9448c57-d51a-4770-dc7c-9c19ccf3c731"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Tritura las galletas hasta hacerlas casi polvo, puedes ayudarte de una licuadora o una\n",
            "procesadora. Si no dispones de estos utensilios, utiliza una bolsa plástica y un rodillo. 2 Derrite\n",
            "la mantequilla hasta que quede líquida y agrégala a las galletas trituradas, mezcla bien hasta\n",
            "formar una pasta uniforme. 3 Traslada la mezcla al molde y extiéndela para hacer la base de la tarta\n",
            "de queso, puedes ayudarte de una paleta o hacerlo directamente con los dedos. Déjala reposar en el\n",
            "refrigerador para que se endurezca mientras preparas el relleno. 4 Lleva la nata a fuego lento y\n",
            "añade, poco a poco, el queso crema y el azúcar, siempre revolviendo con una paleta o batidor. 5 Para\n",
            "añadir la cuajada, lo mejor es seguir las instrucciones de uso en su empaque. En este caso, la\n",
            "disolvimos en 25 ml de leche y la agregamos a la mezcla mientras revolvíamos para una mejor\n",
            "incorporación. 6 Pasados unos 5 minutos luego de añadir la cuajada, retira la mezcla del fuego y\n",
            "deja reposar unos 2-3 minutos. Saca la base de la tarta del refrigerador y vierte el relleno encima\n",
            "de la base de galleta. Déjalo refrigerar. Truco: Si te quedan burbujas al servir el relleno, desliza\n",
            "suavemente una paleta sobre la superficie para eliminarlas. 7 Una vez que el relleno esté\n",
            "suficientemente firme (puedes comprobarlo moviendo un poco el molde o tocándolo suavemente con una\n",
            "paleta en el centro), retíralo del refrigerador y ponle la mermelada encima. Puedes preparar tu\n",
            "propia mermelada casera con nuestra receta de mermelada de fresa light. 8 Deja refrigerar unos 15 o\n",
            "20 minutos más y tu tarta de queso con cuajada estará lista para retirarla del molde y servir.\n",
            "¡Disfruta! Si prefieres una preparación al horno, puedes visitar nuestra receta de tarta de queso al\n",
            "horno.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construcción del vocabulario y tokenización\n",
        "\n",
        "Vamos a usar el tokenizer para español de `spacy`.\n",
        "\n",
        "El objetivo es generar una **lista de n-gramas para entrenar la\n",
        "NN**. e.g con n=4, queremos tuplas de (3 palabras de contexto, 1 target).\n",
        "\n",
        "Vamos a:\n",
        "\n",
        "* Considerar como parte del vocabulario todas las palabras que ocurran al menos dos veces.\n",
        "* Hacer padding con BOS y EOS tokens.\n",
        "* Tokenizar cada documento y convertir a token IDs según el vocab.\n",
        "* Pasar de tokens a n-gramas y generar una sola lista con todos los samples de entrenamiento.\n"
      ],
      "metadata": {
        "id": "gOR6scsQjyay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer con reglas de puntacion, contracciones, etc:\n",
        "import spacy\n",
        "\n",
        "tokenizer = spacy.load('es_core_news_sm')"
      ],
      "metadata": {
        "id": "M6-oSyEvnXFU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veamos un ejemplo:\n",
        "doc = tokenizer(texts_train[0])\n",
        "print(doc.text)\n",
        "for i, token in enumerate(doc):\n",
        "    print(token.text)\n",
        "    if i > 15:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGRXkOtFDqCl",
        "outputId": "e2b8f5ed-0d0a-4342-8a41-09bd897b1e6a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Cocemos el arroz en agua hirviendo con un poco de sal. 2 Picamos los ajos y la cebolla en cuadraditos.Cortamos el tocino en dados. 3 Cortamos las cabezas de la trucha por detrás de las agallas y con un cuchillo afilado, las abrimos de arriba abajo por el vientre. 4 Retiramos las vísceras y todas las membranas negras. 5 Seccionamos la carne a cada lado de la espina sin llegar al dorso. 6 Retiramos las espinas cortando a la altura de la cola. 7 Las lavamos muy bien y secamos con la ayuda de un paño. 8 Salpimentamos por dentro y por fuera.Lavamos las setas y las picamos. 9 Reservamos la mitad. 10 En una sartén con aceite, sofreímos el tocino y la mitad de las setas. 11 Rellenamos las truchas con las setas y el tocino. 12 Cerramos la abertura. 13 Horneamos durante 25 minutos. 14 Rehogamos en mantequilla el resto de las setas. 15 Añadimos el perejil picado, incorporamos el arroz cocido. 16 Vertemos un chorrito de aceite, añadimos el ajo picado, agregamos la cebolla picada y rehogamos dos minutos. 17 Sacamos las truchas del horno. 18 Calentamos el brandy en un cazo, prendemos fuego y vertemos sobre las truchas. 19 Servimos acompañadas del arroz con setas.\n",
            "1\n",
            "Cocemos\n",
            "el\n",
            "arroz\n",
            "en\n",
            "agua\n",
            "hirviendo\n",
            "con\n",
            "un\n",
            "poco\n",
            "de\n",
            "sal\n",
            ".\n",
            "2\n",
            "Picamos\n",
            "los\n",
            "ajos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def create_vocab(docs: list, min_frec=2) -> tuple:\n",
        "    \"\"\"Crea un vocabulario a partir de una lista de docs.\n",
        "    Returns:\n",
        "        Dos diccionarios: token2idx (palabra -> índice) y idx2token (índice -> palabra)\n",
        "    \"\"\"\n",
        "    # NOTE esto se puede acelerar paralelizando la tokenizacion con datasets.map()\n",
        "    # y luego usar e.g. pandas explode().value_counts(). Además, podriamos\n",
        "    # aprovechar y ya guardar el dataset de train tokenizado.\n",
        "    str2count = {}\n",
        "    for doc in tqdm(docs):\n",
        "        for token in tokenizer(doc):\n",
        "            token = token.text\n",
        "            str2count[token] = str2count.get(token, 0) + 1\n",
        "    # filtrar por min_frec:\n",
        "    str2count = {token: count for token, count in str2count.items() if count >= min_frec}\n",
        "    # ordenar de mayor a menor frecuencia:\n",
        "    str2count = dict(sorted(str2count.items(), key=lambda x: x[1], reverse=True))\n",
        "    # Mapeamos cada token a un índice distinto\n",
        "    token2idx = {token: idx for idx, token in enumerate(str2count)}\n",
        "    # Agregamos \"<unk>\", \"<bos>\", \"<eos>\"  al vocab:\n",
        "    token2idx[\"<unk>\"] = len(str2count)\n",
        "    token2idx[\"<bos>\"] = len(str2count) + 1\n",
        "    token2idx[\"<eos>\"] = len(str2count) + 2\n",
        "    # \"Invertir\" el diccionario:\n",
        "    idx2token = {idx: token for idx, token in enumerate(token2idx)}\n",
        "    return token2idx, idx2token\n",
        "\n",
        "\n",
        "token2idx, idx2token = create_vocab(texts_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frt0caaLEr8N",
        "outputId": "df1aa4c8-7bc5-486d-cf36-af6e9e7cd509"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4000/4000 [02:07<00:00, 31.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(token2idx))\n",
        "print(token2idx[\"<unk>\"], token2idx[\"<bos>\"], token2idx[\"<eos>\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJXOkxQ0HUqw",
        "outputId": "a3d609a9-b43c-459a-947a-bcadb585536c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11341\n",
            "11338 11339 11340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import Tensor\n",
        "\n",
        "def tokenize(doc: str, ngram_order: int = 4) -> Tensor:\n",
        "  \"\"\"Convierte documento a tensor de token IDs.\n",
        "  Agrega n-1 BOS y 1 EOS tokens (end-of-seq. y beg-of-seq).\n",
        "  \"\"\"\n",
        "  token_ids = [token2idx.get(token.text, token2idx[\"<unk>\"]) for token in tokenizer(doc)]\n",
        "  # agregamos BOS y EOS tokens:\n",
        "  token_ids = [token2idx[\"<bos>\"]] * (ngram_order - 1) + token_ids + [token2idx[\"<eos>\"]]\n",
        "  return torch.tensor(token_ids, dtype=torch.long)\n",
        "\n",
        "print(texts_train[0])\n",
        "print(tokenize(texts_train[0])[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UtFtN3nFwzX",
        "outputId": "6df1766f-2354-44d2-d6c4-b98061a7f9a7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Cocemos el arroz en agua hirviendo con un poco de sal. 2 Picamos los ajos y la cebolla en cuadraditos.Cortamos el tocino en dados. 3 Cortamos las cabezas de la trucha por detrás de las agallas y con un cuchillo afilado, las abrimos de arriba abajo por el vientre. 4 Retiramos las vísceras y todas las membranas negras. 5 Seccionamos la carne a cada lado de la espina sin llegar al dorso. 6 Retiramos las espinas cortando a la altura de la cola. 7 Las lavamos muy bien y secamos con la ayuda de un paño. 8 Salpimentamos por dentro y por fuera.Lavamos las setas y las picamos. 9 Reservamos la mitad. 10 En una sartén con aceite, sofreímos el tocino y la mitad de las setas. 11 Rellenamos las truchas con las setas y el tocino. 12 Cerramos la abertura. 13 Horneamos durante 25 minutos. 14 Rehogamos en mantequilla el resto de las setas. 15 Añadimos el perejil picado, incorporamos el arroz cocido. 16 Vertemos un chorrito de aceite, añadimos el ajo picado, agregamos la cebolla picada y rehogamos dos minutos. 17 Sacamos las truchas del horno. 18 Calentamos el brandy en un cazo, prendemos fuego y vertemos sobre las truchas. 19 Servimos acompañadas del arroz con setas.\n",
            "tensor([11339, 11339, 11339,    21,  1318,     5,    81,     7,    33,   295,\n",
            "            6,    10,    23,     1,    35,     0,    22,  1190,    11,   195])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def doc2ngrams(doc: str, ngram_order: int = 4) -> list:\n",
        "  \"\"\"Convierte un documento en tuplas de\n",
        "  ([ idx_i-context_size, ..., idx_i-1 ], target_idx), donde cada elemento de la tupla\n",
        "  es un tensor de token IDs.\n",
        "  \"\"\"\n",
        "  token_ids = tokenize(doc, ngram_order=ngram_order)\n",
        "  ngrams_list = [\n",
        "      (token_ids[(i-ngram_order):(i-1)], token_ids[i-1])\n",
        "      for i in range(ngram_order, len(token_ids) + 1)\n",
        "  ]\n",
        "  return ngrams_list"
      ],
      "metadata": {
        "id": "PI9LY8AjMfq0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# por ejemplo:\n",
        "doc_ = texts_train[0]\n",
        "token_ids_ = tokenize(doc_)\n",
        "ngrams_ = doc2ngrams(doc_)\n",
        "\n",
        "print(doc_)\n",
        "print(token_ids_[:10])\n",
        "print(ngrams_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kfR3OzHMgoH",
        "outputId": "8c80db58-e7e3-4947-ce12-cd9d2d4f4048"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Cocemos el arroz en agua hirviendo con un poco de sal. 2 Picamos los ajos y la cebolla en cuadraditos.Cortamos el tocino en dados. 3 Cortamos las cabezas de la trucha por detrás de las agallas y con un cuchillo afilado, las abrimos de arriba abajo por el vientre. 4 Retiramos las vísceras y todas las membranas negras. 5 Seccionamos la carne a cada lado de la espina sin llegar al dorso. 6 Retiramos las espinas cortando a la altura de la cola. 7 Las lavamos muy bien y secamos con la ayuda de un paño. 8 Salpimentamos por dentro y por fuera.Lavamos las setas y las picamos. 9 Reservamos la mitad. 10 En una sartén con aceite, sofreímos el tocino y la mitad de las setas. 11 Rellenamos las truchas con las setas y el tocino. 12 Cerramos la abertura. 13 Horneamos durante 25 minutos. 14 Rehogamos en mantequilla el resto de las setas. 15 Añadimos el perejil picado, incorporamos el arroz cocido. 16 Vertemos un chorrito de aceite, añadimos el ajo picado, agregamos la cebolla picada y rehogamos dos minutos. 17 Sacamos las truchas del horno. 18 Calentamos el brandy en un cazo, prendemos fuego y vertemos sobre las truchas. 19 Servimos acompañadas del arroz con setas.\n",
            "tensor([11339, 11339, 11339,    21,  1318,     5,    81,     7,    33,   295])\n",
            "[(tensor([11339, 11339, 11339]), tensor(21)), (tensor([11339, 11339,    21]), tensor(1318)), (tensor([11339,    21,  1318]), tensor(5)), (tensor([  21, 1318,    5]), tensor(81)), (tensor([1318,    5,   81]), tensor(7)), (tensor([ 5, 81,  7]), tensor(33)), (tensor([81,  7, 33]), tensor(295)), (tensor([  7,  33, 295]), tensor(6)), (tensor([ 33, 295,   6]), tensor(10)), (tensor([295,   6,  10]), tensor(23)), (tensor([ 6, 10, 23]), tensor(1)), (tensor([10, 23,  1]), tensor(35)), (tensor([23,  1, 35]), tensor(0)), (tensor([ 1, 35,  0]), tensor(22)), (tensor([35,  0, 22]), tensor(1190)), (tensor([   0,   22, 1190]), tensor(11)), (tensor([  22, 1190,   11]), tensor(195)), (tensor([1190,   11,  195]), tensor(3)), (tensor([ 11, 195,   3]), tensor(4)), (tensor([195,   3,   4]), tensor(52)), (tensor([ 3,  4, 52]), tensor(7)), (tensor([ 4, 52,  7]), tensor(946)), (tensor([ 52,   7, 946]), tensor(0)), (tensor([  7, 946,   0]), tensor(736)), (tensor([946,   0, 736]), tensor(5)), (tensor([  0, 736,   5]), tensor(977)), (tensor([736,   5, 977]), tensor(7)), (tensor([  5, 977,   7]), tensor(675)), (tensor([977,   7, 675]), tensor(0)), (tensor([  7, 675,   0]), tensor(24)), (tensor([675,   0,  24]), tensor(736)), (tensor([  0,  24, 736]), tensor(12)), (tensor([ 24, 736,  12]), tensor(1417)), (tensor([ 736,   12, 1417]), tensor(1)), (tensor([  12, 1417,    1]), tensor(4)), (tensor([1417,    1,    4]), tensor(2004)), (tensor([   1,    4, 2004]), tensor(18)), (tensor([   4, 2004,   18]), tensor(5811)), (tensor([2004,   18, 5811]), tensor(1)), (tensor([  18, 5811,    1]), tensor(12)), (tensor([5811,    1,   12]), tensor(8735)), (tensor([   1,   12, 8735]), tensor(3)), (tensor([  12, 8735,    3]), tensor(6)), (tensor([8735,    3,    6]), tensor(10)), (tensor([ 3,  6, 10]), tensor(501)), (tensor([  6,  10, 501]), tensor(1967)), (tensor([  10,  501, 1967]), tensor(2)), (tensor([ 501, 1967,    2]), tensor(12)), (tensor([1967,    2,   12]), tensor(2599)), (tensor([   2,   12, 2599]), tensor(1)), (tensor([  12, 2599,    1]), tensor(475)), (tensor([2599,    1,  475]), tensor(487)), (tensor([  1, 475, 487]), tensor(18)), (tensor([475, 487,  18]), tensor(5)), (tensor([487,  18,   5]), tensor(11338)), (tensor([   18,     5, 11338]), tensor(0)), (tensor([    5, 11338,     0]), tensor(26)), (tensor([11338,     0,    26]), tensor(1018)), (tensor([   0,   26, 1018]), tensor(12)), (tensor([  26, 1018,   12]), tensor(4951)), (tensor([1018,   12, 4951]), tensor(3)), (tensor([  12, 4951,    3]), tensor(319)), (tensor([4951,    3,  319]), tensor(12)), (tensor([  3, 319,  12]), tensor(5812)), (tensor([ 319,   12, 5812]), tensor(1809)), (tensor([  12, 5812, 1809]), tensor(0)), (tensor([5812, 1809,    0]), tensor(29)), (tensor([1809,    0,   29]), tensor(11338)), (tensor([    0,    29, 11338]), tensor(4)), (tensor([   29, 11338,     4]), tensor(73)), (tensor([11338,     4,    73]), tensor(9)), (tensor([ 4, 73,  9]), tensor(139)), (tensor([ 73,   9, 139]), tensor(199)), (tensor([  9, 139, 199]), tensor(1)), (tensor([139, 199,   1]), tensor(4)), (tensor([199,   1,   4]), tensor(2146)), (tensor([   1,    4, 2146]), tensor(71)), (tensor([   4, 2146,   71]), tensor(1386)), (tensor([2146,   71, 1386]), tensor(19)), (tensor([  71, 1386,   19]), tensor(7325)), (tensor([1386,   19, 7325]), tensor(0)), (tensor([  19, 7325,    0]), tensor(44)), (tensor([7325,    0,   44]), tensor(1018)), (tensor([   0,   44, 1018]), tensor(12)), (tensor([  44, 1018,   12]), tensor(1062)), (tensor([1018,   12, 1062]), tensor(1516)), (tensor([  12, 1062, 1516]), tensor(9)), (tensor([1062, 1516,    9]), tensor(4)), (tensor([1516,    9,    4]), tensor(2600)), (tensor([   9,    4, 2600]), tensor(1)), (tensor([   4, 2600,    1]), tensor(4)), (tensor([2600,    1,    4]), tensor(2419)), (tensor([   1,    4, 2419]), tensor(0)), (tensor([   4, 2419,    0]), tensor(64)), (tensor([2419,    0,   64]), tensor(473)), (tensor([  0,  64, 473]), tensor(830)), (tensor([ 64, 473, 830]), tensor(59)), (tensor([473, 830,  59]), tensor(28)), (tensor([830,  59,  28]), tensor(3)), (tensor([59, 28,  3]), tensor(2175)), (tensor([  28,    3, 2175]), tensor(6)), (tensor([   3, 2175,    6]), tensor(4)), (tensor([2175,    6,    4]), tensor(224)), (tensor([  6,   4, 224]), tensor(1)), (tensor([  4, 224,   1]), tensor(10)), (tensor([224,   1,  10]), tensor(1133)), (tensor([   1,   10, 1133]), tensor(0)), (tensor([  10, 1133,    0]), tensor(93)), (tensor([1133,    0,   93]), tensor(1556)), (tensor([   0,   93, 1556]), tensor(18)), (tensor([  93, 1556,   18]), tensor(331)), (tensor([1556,   18,  331]), tensor(3)), (tensor([ 18, 331,   3]), tensor(18)), (tensor([331,   3,  18]), tensor(623)), (tensor([  3,  18, 623]), tensor(0)), (tensor([ 18, 623,   0]), tensor(1024)), (tensor([ 623,    0, 1024]), tensor(12)), (tensor([   0, 1024,   12]), tensor(433)), (tensor([1024,   12,  433]), tensor(3)), (tensor([ 12, 433,   3]), tensor(12)), (tensor([433,   3,  12]), tensor(745)), (tensor([  3,  12, 745]), tensor(0)), (tensor([ 12, 745,   0]), tensor(159)), (tensor([745,   0, 159]), tensor(922)), (tensor([  0, 159, 922]), tensor(4)), (tensor([159, 922,   4]), tensor(151)), (tensor([922,   4, 151]), tensor(0)), (tensor([  4, 151,   0]), tensor(99)), (tensor([151,   0,  99]), tensor(60)), (tensor([ 0, 99, 60]), tensor(14)), (tensor([99, 60, 14]), tensor(53)), (tensor([60, 14, 53]), tensor(6)), (tensor([14, 53,  6]), tensor(30)), (tensor([53,  6, 30]), tensor(2)), (tensor([ 6, 30,  2]), tensor(1106)), (tensor([  30,    2, 1106]), tensor(5)), (tensor([   2, 1106,    5]), tensor(977)), (tensor([1106,    5,  977]), tensor(3)), (tensor([  5, 977,   3]), tensor(4)), (tensor([977,   3,   4]), tensor(151)), (tensor([  3,   4, 151]), tensor(1)), (tensor([  4, 151,   1]), tensor(12)), (tensor([151,   1,  12]), tensor(433)), (tensor([  1,  12, 433]), tensor(0)), (tensor([ 12, 433,   0]), tensor(479)), (tensor([433,   0, 479]), tensor(2365)), (tensor([   0,  479, 2365]), tensor(12)), (tensor([ 479, 2365,   12]), tensor(1758)), (tensor([2365,   12, 1758]), tensor(6)), (tensor([  12, 1758,    6]), tensor(12)), (tensor([1758,    6,   12]), tensor(433)), (tensor([  6,  12, 433]), tensor(3)), (tensor([ 12, 433,   3]), tensor(5)), (tensor([433,   3,   5]), tensor(977)), (tensor([  3,   5, 977]), tensor(0)), (tensor([  5, 977,   0]), tensor(443)), (tensor([977,   0, 443]), tensor(2420)), (tensor([   0,  443, 2420]), tensor(4)), (tensor([ 443, 2420,    4]), tensor(7326)), (tensor([2420,    4, 7326]), tensor(0)), (tensor([   4, 7326,    0]), tensor(804)), (tensor([7326,    0,  804]), tensor(1759)), (tensor([   0,  804, 1759]), tensor(36)), (tensor([ 804, 1759,   36]), tensor(774)), (tensor([1759,   36,  774]), tensor(17)), (tensor([ 36, 774,  17]), tensor(0)), (tensor([774,  17,   0]), tensor(1134)), (tensor([  17,    0, 1134]), tensor(3585)), (tensor([   0, 1134, 3585]), tensor(7)), (tensor([1134, 3585,    7]), tensor(111)), (tensor([3585,    7,  111]), tensor(5)), (tensor([  7, 111,   5]), tensor(189)), (tensor([111,   5, 189]), tensor(1)), (tensor([  5, 189,   1]), tensor(12)), (tensor([189,   1,  12]), tensor(433)), (tensor([  1,  12, 433]), tensor(0)), (tensor([ 12, 433,   0]), tensor(180)), (tensor([433,   0, 180]), tensor(370)), (tensor([  0, 180, 370]), tensor(5)), (tensor([180, 370,   5]), tensor(148)), (tensor([370,   5, 148]), tensor(202)), (tensor([  5, 148, 202]), tensor(2)), (tensor([148, 202,   2]), tensor(563)), (tensor([202,   2, 563]), tensor(5)), (tensor([  2, 563,   5]), tensor(81)), (tensor([563,   5,  81]), tensor(482)), (tensor([  5,  81, 482]), tensor(0)), (tensor([ 81, 482,   0]), tensor(1533)), (tensor([ 482,    0, 1533]), tensor(1237)), (tensor([   0, 1533, 1237]), tensor(10)), (tensor([1533, 1237,   10]), tensor(407)), (tensor([1237,   10,  407]), tensor(1)), (tensor([ 10, 407,   1]), tensor(30)), (tensor([407,   1,  30]), tensor(2)), (tensor([ 1, 30,  2]), tensor(98)), (tensor([30,  2, 98]), tensor(5)), (tensor([ 2, 98,  5]), tensor(79)), (tensor([98,  5, 79]), tensor(202)), (tensor([  5,  79, 202]), tensor(2)), (tensor([ 79, 202,   2]), tensor(268)), (tensor([202,   2, 268]), tensor(4)), (tensor([  2, 268,   4]), tensor(52)), (tensor([268,   4,  52]), tensor(289)), (tensor([  4,  52, 289]), tensor(3)), (tensor([ 52, 289,   3]), tensor(1483)), (tensor([ 289,    3, 1483]), tensor(124)), (tensor([   3, 1483,  124]), tensor(17)), (tensor([1483,  124,   17]), tensor(0)), (tensor([124,  17,   0]), tensor(2119)), (tensor([  17,    0, 2119]), tensor(978)), (tensor([   0, 2119,  978]), tensor(12)), (tensor([2119,  978,   12]), tensor(1758)), (tensor([ 978,   12, 1758]), tensor(25)), (tensor([  12, 1758,   25]), tensor(38)), (tensor([1758,   25,   38]), tensor(0)), (tensor([25, 38,  0]), tensor(1810)), (tensor([  38,    0, 1810]), tensor(1484)), (tensor([   0, 1810, 1484]), tensor(5)), (tensor([1810, 1484,    5]), tensor(1372)), (tensor([1484,    5, 1372]), tensor(7)), (tensor([   5, 1372,    7]), tensor(10)), (tensor([1372,    7,   10]), tensor(312)), (tensor([  7,  10, 312]), tensor(2)), (tensor([ 10, 312,   2]), tensor(11338)), (tensor([  312,     2, 11338]), tensor(34)), (tensor([    2, 11338,    34]), tensor(3)), (tensor([11338,    34,     3]), tensor(700)), (tensor([ 34,   3, 700]), tensor(91)), (tensor([  3, 700,  91]), tensor(12)), (tensor([700,  91,  12]), tensor(1758)), (tensor([  91,   12, 1758]), tensor(0)), (tensor([  12, 1758,    0]), tensor(3096)), (tensor([1758,    0, 3096]), tensor(843)), (tensor([   0, 3096,  843]), tensor(1811)), (tensor([3096,  843, 1811]), tensor(25)), (tensor([ 843, 1811,   25]), tensor(81)), (tensor([1811,   25,   81]), tensor(6)), (tensor([25, 81,  6]), tensor(433)), (tensor([ 81,   6, 433]), tensor(0)), (tensor([  6, 433,   0]), tensor(11340))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# armamos todos los ngrams de training:\n",
        "ngrams_train = []\n",
        "for doc in tqdm(texts_train):\n",
        "  ngrams_train.extend(doc2ngrams(doc, ngram_order=4))"
      ],
      "metadata": {
        "id": "FW93Ku_RLfHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff9c4716-2ca8-46c4-c632-408934fe761f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4000/4000 [02:09<00:00, 30.98it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ngrams_train[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1ye2KkYQBwQ",
        "outputId": "7f322e7d-70fd-4afc-977d-8ebb81173486"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor([11339, 11339, 11339]), tensor(21)), (tensor([11339, 11339,    21]), tensor(1318))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Armado de _batches_\n",
        "\n",
        "Armamos los batches para entrenar el modelo. Para esto usamos la clase `DataLoader` de PyTorch. En cada iteración, el `DataLoader` nos devuelve un batch de ejemplos. No necesitamos una _collate function_ porque ya todos los ejemplos tienen igual dimensión (no necesitamos padding)."
      ],
      "metadata": {
        "id": "9YjMSjHnLmtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(ngrams_train, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "YvTLRl7JLnE1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veamos los primeros dos batches de entrenamiento:\n",
        "torch.manual_seed(33)\n",
        "for i, data in enumerate(train_loader):\n",
        "    print(f\"### batch {i}\")\n",
        "    print(f\"Shapes = {[s.shape for s in data]}\")\n",
        "    print(\"Primeros 5 ejemplos:\")\n",
        "    print(\"- Features:\")\n",
        "    print(data[0][:5])\n",
        "    print(\"- Targets:\")\n",
        "    print(data[1][:5])\n",
        "    print()\n",
        "    if i == 1:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cBUbcqEMYNR",
        "outputId": "e1742d29-558c-4515-d828-72d105122323"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### batch 0\n",
            "Shapes = [torch.Size([32, 3]), torch.Size([32])]\n",
            "Primeros 5 ejemplos:\n",
            "- Features:\n",
            "tensor([[  16,   12, 1805],\n",
            "        [  39, 1214,    6],\n",
            "        [ 457,    8,    5],\n",
            "        [  61,    5,   33],\n",
            "        [   0,   60,   10]])\n",
            "- Targets:\n",
            "tensor([  2, 133,  51, 321, 120])\n",
            "\n",
            "### batch 1\n",
            "Shapes = [torch.Size([32, 3]), torch.Size([32])]\n",
            "Primeros 5 ejemplos:\n",
            "- Features:\n",
            "tensor([[ 88,   0,  72],\n",
            "        [ 77,   9,  10],\n",
            "        [  3,   4, 291],\n",
            "        [  2,  84,  15],\n",
            "        [499,   2,  16]])\n",
            "- Targets:\n",
            "tensor([   46,   120,     3, 11338,   154])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo\n",
        "\n",
        "Armamos una red bien sencilla con una hidden layer. Es la misma arquitectura que Figure 7.17 de [Jurafksy](https://web.stanford.edu/~jurafsky/slp3/). Usamos embeddings con inicialización random pero podríamos empezar con embeddings pre-entrenados.\n",
        "\n",
        "NOTE: Como vamos a usar [Cross Entropy Loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html), no tenemos que aplicar softmax porque espera \"raw, unnormalized scores for each class\" i.e. logits."
      ],
      "metadata": {
        "id": "Dtx-oJRAcsRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class NGramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, ngram_order):\n",
        "        super().__init__()\n",
        "        context_size = ngram_order - 1\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(context_size * embedding_dim, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs) # shape (bsz, context_size, embed_dim)\n",
        "        concatenated_embeds = embeds.flatten(1) # shape (bsz, context_size * embed_dim)\n",
        "        hidden = F.relu(self.linear1(concatenated_embeds)) # shape (bsz, hidden_size)\n",
        "        logits = self.linear2(hidden) # shape (bsz, vocab_size)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "j_xcKS3NcrB3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento\n"
      ],
      "metadata": {
        "id": "6Ec3_tL41LDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciamos el modelo\n",
        "neural_lm = NGramLanguageModel(\n",
        "    vocab_size=len(token2idx),\n",
        "    embedding_dim=50,\n",
        "    hidden_size=32,\n",
        "    ngram_order=4,\n",
        ")\n",
        "neural_lm = neural_lm.to(device)"
      ],
      "metadata": {
        "id": "zpWEyxzrQlM-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcion de pérdida y optimizador\n",
        "from torch import optim\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(neural_lm.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "sSGYXaczQgFr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop de entrenamiento (sin datos de validación)\n",
        "\n",
        "def train_epoch(model, optimizer, train_loader, log_steps=2000, device=None):\n",
        "    \"\"\"Entrena 1 epoch\n",
        "    \"\"\"\n",
        "    total_loss = 0\n",
        "    steps_done = 0\n",
        "    n_steps = len(train_loader)\n",
        "    for context, target in tqdm(train_loader, total=n_steps):\n",
        "        context = context.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(context)\n",
        "        loss = loss_fn(logits, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        steps_done += 1\n",
        "        train_loss = total_loss / steps_done\n",
        "        if steps_done % log_steps == 0:\n",
        "            print(f\"    [steps={steps_done}] train_loss: {train_loss:.4f}\")\n",
        "    return train_loss\n",
        "\n",
        "def train(\n",
        "    model, optimizer, train_loader, n_epochs, device=None):\n",
        "  \"\"\"Entrena el modelo durante n_epochs.\n",
        "  \"\"\"\n",
        "  for epoch in range(n_epochs):\n",
        "      print(f\"Epoch {epoch} / {n_epochs}\")\n",
        "      epoch_loss = train_epoch(model, optimizer, train_loader, device=device)\n",
        "      print(f\"Training loss = {epoch_loss:.3f}\")"
      ],
      "metadata": {
        "id": "ZZx2A2qN2Gjy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entrenamos!\n",
        "num_epochs = 1\n",
        "train(neural_lm, optimizer, train_loader, num_epochs, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR6yqrAU2EhI",
        "outputId": "5f9054e3-f3d0-49ac-eb72-0a52b534132e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 / 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 2074/30585 [00:05<00:54, 518.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=2000] train_loss: 6.0745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 4059/30585 [00:09<00:59, 445.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=4000] train_loss: 5.7148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 6077/30585 [00:13<00:45, 539.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=6000] train_loss: 5.5256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▋       | 8100/30585 [00:16<00:41, 539.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=8000] train_loss: 5.3946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 10088/30585 [00:20<00:44, 465.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=10000] train_loss: 5.2836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 12077/30585 [00:24<00:34, 531.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=12000] train_loss: 5.2074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 14076/30585 [00:28<00:30, 532.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=14000] train_loss: 5.1424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 16083/30585 [00:32<00:26, 537.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=16000] train_loss: 5.0919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 18084/30585 [00:36<00:23, 526.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=18000] train_loss: 5.0487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 20095/30585 [00:40<00:20, 523.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=20000] train_loss: 5.0096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 22082/30585 [00:44<00:16, 530.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=22000] train_loss: 4.9775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 24104/30585 [00:48<00:12, 516.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=24000] train_loss: 4.9500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 26066/30585 [00:52<00:08, 532.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=26000] train_loss: 4.9257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 28081/30585 [00:55<00:04, 542.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=28000] train_loss: 4.9031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 30069/30585 [01:00<00:01, 432.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [steps=30000] train_loss: 4.8829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30585/30585 [01:01<00:00, 499.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss = 4.877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generación de texto"
      ],
      "metadata": {
        "id": "u6pPesmuTke6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text2input(context_str: str, ngram_order: int = 4) -> Tensor:\n",
        "    \"\"\"Convierte contexto en un input para la NN (tensor de input IDs)\n",
        "    \"\"\"\n",
        "    ngrams = doc2ngrams(context_str, ngram_order=ngram_order)\n",
        "    # el input es el \"contexto\" del ultimo ngram\n",
        "    last_context = ngrams[-1][0]\n",
        "    # agregamos una dimension que hace las veces de batch (size=1) para hacer el forward\n",
        "    out = last_context.unsqueeze(0)\n",
        "    return out"
      ],
      "metadata": {
        "id": "tNejXRk8TkJd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo:\n",
        "print(text2input(\"usamos la\", ngram_order=4))\n",
        "print(text2input(\"\", ngram_order=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIIOTcIfT_cg",
        "outputId": "ea925455-dfc2-4517-deb7-a58c90b93d11"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[11339,  3411,     4]])\n",
            "tensor([[11339, 11339, 11339]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_text(model, start_text, max_length=10, ngram_order=4, greedy=False):\n",
        "    \"\"\"Generación autorregresiva aleatoria de texto sampleando de softmax.\n",
        "    El modelo debe ser consistente con ngram_order.\n",
        "    \"\"\"\n",
        "    # buscamos los input IDs segun el context size\n",
        "    input_ = text2input(start_text, ngram_order=ngram_order)\n",
        "    # mandamos inputs al mismo device que el modelo\n",
        "    device = next(model.parameters()).device\n",
        "    input_ = input_.to(device)\n",
        "    idx_eos = token2idx[\"<eos>\"]\n",
        "    context_size = ngram_order - 1\n",
        "    # el resultado solo va a incluir el contexto usado + el texto nuevo\n",
        "    idxs_result = input_.clone()\n",
        "    with torch.inference_mode():\n",
        "        for i in range(max_length):\n",
        "            logits = model(input_) # logits\n",
        "            probas = F.softmax(logits, dim=1) # probas\n",
        "            if greedy:\n",
        "                sampled_idx = torch.argmax(probas, dim=1).unsqueeze(1)\n",
        "            else:\n",
        "                # sample:\n",
        "                sampled_idx = torch.multinomial(probas, num_samples=1)\n",
        "            # actualizamos el resultado\n",
        "            idxs_result = torch.cat((idxs_result, sampled_idx), dim=1)\n",
        "            # actualizamos el input conservando solo los ultimos context_size tokens\n",
        "            input_ = idxs_result[:,-context_size:]\n",
        "            if sampled_idx == idx_eos:\n",
        "                break\n",
        "        tokens_result = [idx2token[idx.item()] for idx in idxs_result.squeeze()]\n",
        "        return tokens_result"
      ],
      "metadata": {
        "id": "KeMVbCy-XjQk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0eTXvVzYcpI",
        "outputId": "9fe5cab0-f496-4ef6-feae-0bcb3935bdca"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Cortar los calamares en tiras delgadas y se ponen en remojo unas 3 horas con la leche. 2 En un recipiente hondo, se pone la harina, una cucharada de aceite, sal y un dl. de agua. 3 Con todo esto se forma una masa espesa. 4 Se ponen los calamares en la masa, se escurren y se fríen en abundante aceite caliente. 5 Se sirve con unos gajos de limón. 6 Para 4 personas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "start_text = \"1 Cortar los calamares\"\n",
        "res_ = sample_text(neural_lm, start_text, ngram_order=4, max_length=50)\n",
        "\n",
        "print(\" \".join(res_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqmaBcdKYUzs",
        "outputId": "4248a402-bde0-4b2e-a3e0-760a2336fede"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cortar los calamares otras . lista en la bandeja para que los trozos , pon a fuego , se pone , colamos EL intacto la mantequilla y las croquetas y ¡ minutos más , vacía y retiramos a 200 ºC : más verde , a doren por encima de este tamaño de manzana\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(22)\n",
        "start_text = \"\"\n",
        "res_ = sample_text(neural_lm, start_text, ngram_order=4, max_length=50)\n",
        "\n",
        "print(\" \".join(res_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar_a_qZlZDPo",
        "outputId": "bdeb824a-a007-426d-d2de-01e95a4be455"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bos> <bos> <bos> 1 Para los bordes poniendo este caso de su salsa de coco caldoso , se le picado . Mezcla con la base de quinoa . <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_text = \"\"\n",
        "res_ = sample_text(neural_lm, start_text, ngram_order=4, max_length=50, greedy=True)\n",
        "\n",
        "print(\" \".join(res_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAIkC8j22Ug_",
        "outputId": "0f6f79cf-2e0a-4bca-95f2-dbcc09c2a5f0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bos> <bos> <bos> 1 Para empezar a preparar la salsa de la receta de la salsa de la receta de la salsa de la receta de la salsa de la receta de la salsa de la receta de la salsa de la receta de la salsa de la receta de la salsa de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación\n",
        "\n",
        "Computamos perplexity (PPL) en test.\n",
        "\n",
        "* Hacemos $ \\exp(\\log PPL ) $ para evitar underflow.\n",
        "* Vean que $\\log PPL = CrossEntropy = -avg(\\log(probas))$"
      ],
      "metadata": {
        "id": "yYd_4p8Q9Rcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ngrams_test = []\n",
        "for doc in tqdm(texts_test):\n",
        "  ngrams_test.extend(doc2ngrams(doc, ngram_order=4))"
      ],
      "metadata": {
        "id": "UvaJlCzZ4Br-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46f81fc-0625-4373-972f-651c52e66831"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4000/4000 [02:12<00:00, 30.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(ngrams_test, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "DlxeAZ9G4PaZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(model, dataloader, device):\n",
        "    with torch.no_grad():\n",
        "        # Iteramos por batch. Vamos a ir guardando las probas de los tokens correctos en cada batch.\n",
        "        all_log_probs_gt = torch.tensor([], device=device) # gt: ground truth\n",
        "        for context, target in dataloader:\n",
        "            context = context.to(device)\n",
        "            target = target.to(device)\n",
        "            batch_size = len(target)\n",
        "            logits = model(context) # shape (bsz, vocab_size)\n",
        "            log_probs = F.log_softmax(logits, dim=1) # shape (bsz, vocab_size)\n",
        "            # log_probs_gt:\n",
        "            log_probs_gt = log_probs[torch.arange(batch_size), target] # shape (bsz)\n",
        "            all_log_probs_gt = torch.cat((all_log_probs_gt, log_probs_gt))\n",
        "        # Calculamos PPL:\n",
        "        ce = -all_log_probs_gt.mean()\n",
        "        res = torch.exp(ce)\n",
        "    return res.item()"
      ],
      "metadata": {
        "id": "IsuUZCu25Gr_"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ppl = perplexity(neural_lm, test_loader, device)\n",
        "print(f\"Test PPL = {test_ppl:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWAjtowSLFuA",
        "outputId": "4f96c4cf-b12d-4a35-b393-6db206cb38f8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test PPL = 90.643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yqw28QzI6Tkf"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}