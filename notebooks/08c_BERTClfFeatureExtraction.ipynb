{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/NLP/blob/main/notebooks/08c_BERTClfFeatureExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c5d72f4",
      "metadata": {
        "id": "3c5d72f4"
      },
      "source": [
        "Vamos a usar BERT como feature extractor para resolver un problema de clasificación.\n",
        "\n",
        "Una vez que obtenemos una representación vectorial de la secuencia de input, entrenamos un clasificador que podemos usar para predecir en datos nuevos.\n",
        "\n",
        "-----------------------\n",
        "\n",
        "Tarea: responder donde dice **PREGUNTA**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuración del entorno\n"
      ],
      "metadata": {
        "id": "uCBjQiwCuUkL"
      },
      "id": "uCBjQiwCuUkL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fd9cda8",
      "metadata": {
        "collapsed": true,
        "id": "6fd9cda8"
      },
      "outputs": [],
      "source": [
        "!pip install -qU transformers datasets evaluate watermark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import datasets\n",
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "bTpRjPl0NDol"
      },
      "id": "bTpRjPl0NDol",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "033b75c5",
      "metadata": {
        "id": "033b75c5"
      },
      "outputs": [],
      "source": [
        "%reload_ext watermark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%watermark -vmp torch,transformers,datasets,evaluate,sklearn"
      ],
      "metadata": {
        "id": "BGvuNdbWNVop"
      },
      "id": "BGvuNdbWNVop",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para usar GPU, arriba a la derecha seleccionar \"Change runtime type\" --> \"T4 GPU\""
      ],
      "metadata": {
        "id": "WNAESIFVukMJ"
      },
      "id": "WNAESIFVukMJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "602ba8a0",
      "metadata": {
        "id": "602ba8a0"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cfd724d",
      "metadata": {
        "id": "4cfd724d"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Vamos a resolver una de las tasks de GLUE:\n",
        "\n",
        "[CoLA](https://nyu-mll.github.io/CoLA/) (Corpus of Linguistic Acceptability). El objetivo es determinar is una oración es gramaticalmente correcta (1) o no (0)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = load_dataset(\"glue\", \"cola\")"
      ],
      "metadata": {
        "id": "639XMHuvNfsr"
      },
      "id": "639XMHuvNfsr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset"
      ],
      "metadata": {
        "id": "Mx5nfBzQN9EW"
      },
      "id": "Mx5nfBzQN9EW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset[\"train\"].features"
      ],
      "metadata": {
        "id": "jsOMFNhIQttQ"
      },
      "id": "jsOMFNhIQttQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_random_elements(dataset, num_examples=10):\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = np.random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = np.random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))\n",
        "\n",
        "show_random_elements(full_dataset[\"train\"], num_examples=10)"
      ],
      "metadata": {
        "id": "_Hprsx_fOpoB"
      },
      "id": "_Hprsx_fOpoB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Distribucion de clases:\")\n",
        "for k in full_dataset.keys():\n",
        "    print(k)\n",
        "    print(pd.Series(full_dataset[k][\"label\"]).value_counts())\n",
        "    print(\"-\"*70)\n"
      ],
      "metadata": {
        "id": "q543kHFeP_L0"
      },
      "id": "q543kHFeP_L0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset[\"test\"][:3]"
      ],
      "metadata": {
        "id": "a6TUhv1jQc00"
      },
      "id": "a6TUhv1jQc00",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREGUNTA 9**: ¿por qué el set de test no tiene labels?"
      ],
      "metadata": {
        "id": "U5QVI9TNwFN1"
      },
      "id": "U5QVI9TNwFN1"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sentence length:\")\n",
        "for k in full_dataset.keys():\n",
        "    print(k)\n",
        "    largos = pd.Series(full_dataset[k][\"sentence\"]).str.len()\n",
        "    print(np.quantile(largos, q=np.arange(0, 1.1, .1)).astype(int))\n",
        "    print(\"-\"*70)"
      ],
      "metadata": {
        "id": "on3dyXrgTZrj"
      },
      "id": "on3dyXrgTZrj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "846d83b1",
      "metadata": {
        "id": "846d83b1"
      },
      "source": [
        "## Tokenización y feature extraction\n",
        "\n",
        "Vamos a cargar un modelo sin head porque solo nos interesa BERT para extraer features del texto."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"distilbert-base-cased\""
      ],
      "metadata": {
        "id": "uEZQOcF0UFow"
      },
      "id": "uEZQOcF0UFow",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "iOcLBkGAUctE"
      },
      "id": "iOcLBkGAUctE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea762ba",
      "metadata": {
        "id": "5ea762ba"
      },
      "outputs": [],
      "source": [
        "print(\"max length:\", tokenizer.model_max_length)\n",
        "print(\"Vocab size:\", tokenizer.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cuando lo apliquemos, esto va a truncar segun la longitud maxima del batch\n",
        "def tokenize_fn(examples):\n",
        "    return tokenizer(examples[\"sentence\"], truncation=True, padding=True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "tBZFm6EfUsm8"
      },
      "id": "tBZFm6EfUsm8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicamos con batches iguales a cada particion (train, val, test) i.e. train es un gran batch\n",
        "# Entonces cada ejemplo va a tener length = max length de su particion\n",
        "# Hacemos esto porque solo vamos a hacer inferencia, no entrenar\n",
        "tokenized_dataset = full_dataset.map(tokenize_fn, batched=True, batch_size=None)"
      ],
      "metadata": {
        "id": "QUlscMWLhjG2"
      },
      "id": "QUlscMWLhjG2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE para datasets grandes, suele convenir ir procesando los ejemplos on-the-fly."
      ],
      "metadata": {
        "id": "snZizM42WMdh"
      },
      "id": "snZizM42WMdh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ya truncamos segun la maxima longitud de train/val/test:\n",
        "for split, ds in tokenized_dataset.items():\n",
        "    ejemplos = ds[:3][\"input_ids\"]\n",
        "    print(split)\n",
        "    print([len(x) for x in ejemplos])"
      ],
      "metadata": {
        "id": "jWyeFU6XjSS-"
      },
      "id": "jWyeFU6XjSS-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d4103c3",
      "metadata": {
        "id": "6d4103c3"
      },
      "outputs": [],
      "source": [
        "# del full_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# automodel a secas no agrega ninguna capa (head) al modelo (body)\n",
        "model = AutoModel.from_pretrained(model_checkpoint)\n",
        "_ = model.to(device)"
      ],
      "metadata": {
        "id": "ftbuXhaIV0PI"
      },
      "id": "ftbuXhaIV0PI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hacemos el forward pass en batches\n",
        "batch_size = 10"
      ],
      "metadata": {
        "id": "XgxwMTIdjqja"
      },
      "id": "XgxwMTIdjqja",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07122e49",
      "metadata": {
        "id": "07122e49"
      },
      "outputs": [],
      "source": [
        "# Representamos cada input con el embedding CLS\n",
        "# --> extraemos el embedding de CLS en un batch de prueba\n",
        "\n",
        "batch_prueba = {\n",
        "    \"attention_mask\": torch.tensor(tokenized_dataset[\"train\"][:batch_size][\"attention_mask\"], device=device),\n",
        "    \"input_ids\": torch.tensor(tokenized_dataset[\"train\"][:batch_size][\"input_ids\"], device=device),\n",
        "}\n",
        "model.eval()\n",
        "with torch.inference_mode(): # como no_grad() pero mejor https://pytorch.org/docs/stable/generated/torch.inference_mode.html\n",
        "    output_prueba = model(**batch_prueba)\n",
        "cls_token_output = output_prueba.last_hidden_state[:, 0]\n",
        "\n",
        "print(output_prueba.last_hidden_state.shape)\n",
        "print(cls_token_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316d0450",
      "metadata": {
        "id": "316d0450"
      },
      "outputs": [],
      "source": [
        "def get_embeddings(examples):\n",
        "    \"\"\"Usamos embedding de CLS para representar cada secuencia\n",
        "    De qué otra manera podemos extraer embeddings?\n",
        "    \"\"\"\n",
        "    inputs = {key: torch.tensor(data, device=device) for key, data in examples.items() if key in ['input_ids', 'attention_mask']}\n",
        "    with torch.inference_mode():\n",
        "        output = model(**inputs).last_hidden_state[:, 0]\n",
        "    return {\"features\": output.cpu()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2629aaa3",
      "metadata": {
        "id": "2629aaa3"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "featurized_dataset = tokenized_dataset.map(get_embeddings, batched=True, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(featurized_dataset[\"train\"][\"features\"]), len(featurized_dataset[\"train\"][\"features\"][0])"
      ],
      "metadata": {
        "id": "kyxJ4hg4URTp"
      },
      "id": "kyxJ4hg4URTp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fe91178",
      "metadata": {
        "id": "0fe91178"
      },
      "outputs": [],
      "source": [
        "# usamos arrays de numpy para entrenar/evaluar el modelo\n",
        "X_train = np.array(featurized_dataset[\"train\"][\"features\"])\n",
        "y_train = np.array(featurized_dataset[\"train\"][\"label\"])\n",
        "\n",
        "X_val = np.array(featurized_dataset[\"validation\"][\"features\"])\n",
        "y_val = np.array(featurized_dataset[\"validation\"][\"label\"])\n",
        "\n",
        "X_test = np.array(featurized_dataset[\"test\"][\"features\"])\n",
        "y_test = np.array(featurized_dataset[\"test\"][\"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREGUNTA 10**: ¿qué dimensión tiene cada ejemplo \"vectorizado\"? ¿Qué tipo de _pooling_ usamos para extraer los vectores?"
      ],
      "metadata": {
        "id": "sPkYcb35w1YD"
      },
      "id": "sPkYcb35w1YD"
    },
    {
      "cell_type": "markdown",
      "id": "e76e2e95-e9b3-4a54-b778-0bdcef59f098",
      "metadata": {
        "id": "e76e2e95-e9b3-4a54-b778-0bdcef59f098"
      },
      "source": [
        "## Modelo\n",
        "\n",
        "Entrenado sobre los BERT embeddings ya extraidos.\n",
        "\n",
        "Vamos a hacer _error analysis_ (inspeccionar los ejemplos peor puntuados por el modelo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "201a4329-7a91-4501-9c75-4d18f4646fa5",
      "metadata": {
        "id": "201a4329-7a91-4501-9c75-4d18f4646fa5"
      },
      "outputs": [],
      "source": [
        "mod = LogisticRegression(max_iter=1000)\n",
        "mod.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREGUNTA 11**: ¿qué otro modelo podríamos usar en lugar de la regresión logística? ¿qué ventajas / desventajas tiene la reg. logística?"
      ],
      "metadata": {
        "id": "3mM-tMQ5xIDh"
      },
      "id": "3mM-tMQ5xIDh"
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load('glue', \"cola\") # matthews corr coefficient"
      ],
      "metadata": {
        "id": "eF9IDyb_kVJQ"
      },
      "id": "eF9IDyb_kVJQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_train = mod.predict_proba(X_train)[:, 1]\n",
        "pred_train = scores_train.round() # clf con argmax (no ideal)\n",
        "metric.compute(predictions=pred_train, references=y_train)"
      ],
      "metadata": {
        "id": "QyO3m9vJk322"
      },
      "id": "QyO3m9vJk322",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_val = mod.predict_proba(X_val)[:, 1]\n",
        "pred_val = scores_val.round()\n",
        "metric.compute(predictions=pred_val, references=y_val)"
      ],
      "metadata": {
        "id": "KckrNG6FktIu"
      },
      "id": "KckrNG6FktIu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = pd.DataFrame({\"y\": y_val, \"score\": scores_val, \"idx\": featurized_dataset[\"validation\"][\"idx\"]})"
      ],
      "metadata": {
        "id": "4iIo8q4RmrDh"
      },
      "id": "4iIo8q4RmrDh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# falsos positivos más fuertes (y=0 --> no aceptable)\n",
        "top_fp = df_val.query(\"y == 0\").sort_values(\"score\", ascending=False).head(5)\n",
        "top_fp"
      ],
      "metadata": {
        "id": "EeNtMhs5nZIA"
      },
      "id": "EeNtMhs5nZIA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featurized_dataset[\"validation\"].select(top_fp[\"idx\"])[\"sentence\"]"
      ],
      "metadata": {
        "id": "XRDPe3gIoAi2"
      },
      "id": "XRDPe3gIoAi2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# falsos negativos mas fuertes (y=1 --> aceptable)\n",
        "top_fn = df_val.query(\"y == 1\").sort_values(\"score\", ascending=True).head(5)\n",
        "top_fn"
      ],
      "metadata": {
        "id": "aODu8JQTnml3"
      },
      "id": "aODu8JQTnml3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featurized_dataset[\"validation\"].select(top_fn[\"idx\"])[\"sentence\"]"
      ],
      "metadata": {
        "id": "1AcLXXDHnUBO"
      },
      "id": "1AcLXXDHnUBO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Referencias\n",
        "\n",
        "* [Notebooks de rasbt](https://github.com/rasbt/deeplearning-models#transformers)\n",
        "* [Notebooks de HuggingFace](https://huggingface.co/docs/transformers/notebooks)"
      ],
      "metadata": {
        "id": "NCttEJ1qBImq"
      },
      "id": "NCttEJ1qBImq"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v8x3_qKIRkm6"
      },
      "id": "v8x3_qKIRkm6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}