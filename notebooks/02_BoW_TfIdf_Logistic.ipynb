{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/NLP/blob/main/notebooks/02_BoW_TfIdf_Logistic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0WkbF87pmLG"
      },
      "source": [
        "Vamos entrenar sistemas de clasificación de texto con BoW/TF-IDF + Reg. Logística poniendo especial énfasis en los pasos más importantes que tenemos que seguir para resolver tareas de clasificación con Machine Learning.\n",
        "\n",
        "---\n",
        "\n",
        "TAREA: responder donde dice **PREGUNTA**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install watermark datasets"
      ],
      "metadata": {
        "id": "nu-eaCZsQwyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odlxWo0MpmLR"
      },
      "outputs": [],
      "source": [
        "%load_ext watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jNGpfQlpmLV"
      },
      "outputs": [],
      "source": [
        "%watermark -udvp numpy,pandas,datasets,sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLL2OpIYpmLX"
      },
      "source": [
        "### Datos\n",
        "\n",
        "**IMPORTANTE**\n",
        "\n",
        "* Siempre investigar un poco acerca del dataset antes de explorarlo (e.g. leer repositorios o papers asociados, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOyosDxOpmLX"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"tweet_eval\", \"emotion\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsRuZklYpmLZ"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTX1Rm3RpmLZ"
      },
      "source": [
        "**IMPORTANTE**\n",
        "\n",
        "* Siempre explorar los datos para saber qué problemas puede haber (e.g. datos faltantes, labels inesperados en alguna partición del dataset, documentos muy largos, caracteres raros en el input, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4ZvUap_pmLa"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBFiQgUVpmLa"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqjb4usdpmLa"
      },
      "outputs": [],
      "source": [
        "# Convertimos los labels a strings por comodidad\n",
        "int2label = dataset[\"train\"].features[\"label\"].int2str\n",
        "dataset = dataset.map(lambda example: {\"label_str\": int2label(example[\"label\"])}, remove_columns=[\"label\"])\n",
        "dataset = dataset.rename_column(\"label_str\", \"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1Htv2TBpmLb"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdAQLd7XpmLb"
      },
      "outputs": [],
      "source": [
        "# Convertimos a pandas por comodidad\n",
        "import pandas as pd\n",
        "pd.options.display.max_colwidth = 300\n",
        "\n",
        "df_train = dataset[\"train\"].to_pandas()\n",
        "df_val = dataset[\"validation\"].to_pandas()\n",
        "df_test = dataset[\"test\"].to_pandas()\n",
        "#del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58EwvQaepmLb"
      },
      "outputs": [],
      "source": [
        "df_train.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrNNs034pmLc"
      },
      "outputs": [],
      "source": [
        "for df in [df_train, df_val, df_test]:\n",
        "    print(df[\"label\"].value_counts(normalize=False))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXYtPaKLpmLc"
      },
      "source": [
        "**IMPORTANTE**\n",
        "\n",
        "* El preprocesamiento del texto (las transformaciones que hagamos antes de correr modelos) depende del dominio de los datos, de las características del dataset particular, de los modelos vayamos a usar, de la tarea que queremos resolver, etc.\n",
        "* Muchas veces lo mejor es evaluar si algún paso de preprocesamiento altera el rendimiento del modelo antes de aplicarlo, como vamos a ver más adelante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtAYBhNkpmLc"
      },
      "outputs": [],
      "source": [
        "# Vamos a hacer algo sencillo A MODO DE EJEMPLO.\n",
        "# Convertimos 3 o mas letras repetidas a 3 letras: \"hellooooo\" -> \"hellooo\"\n",
        "import re\n",
        "\n",
        "re.sub(r\"(\\w)\\1{2,}\", r\"\\1\\1\\1\", \"hellooooo is there anyboooody in theere?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdbdxd9CpmLc"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub(r\"(\\w)\\1{2,}\", r\"\\1\\1\\1\", text)\n",
        "    text = text.strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_text(\"hellooooo is there anyboooody in theere?\")"
      ],
      "metadata": {
        "id": "CMbKajfpADh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for df in [df_train, df_val, df_test]:\n",
        "    df[\"text\"] = df[\"text\"].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "GT5Ie3EEASE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREUNTA** ¿qué pasos de preprocesamiento aplicarían en esta tarea?"
      ],
      "metadata": {
        "id": "gpNKSbMj1uoS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2PJ0n5IpmLd"
      },
      "source": [
        "### Estrategia de evaluación\n",
        "\n",
        "**IMPORTANTE**:\n",
        "\n",
        "* Antes de definir qué modelos queremos probar y qué hiperparámetros queremos tunear, debemos definir cómo vamos a evaluar los modelos. En particular:\n",
        "\n",
        "1. Métrica de evaluación\n",
        "   * Tenemos un dataset de clasificación multiclase desbalanceado donde ninguna clase parece ser más importante que el resto\n",
        "   * **PREGUNTA 1** ¿qué métrica podríamos usar?\n",
        "\n",
        "2. Partición de datos (e.g. un único test set, holdout aka validation aka dev set, cross-validation)\n",
        "   * El dataset ya viene con una partición train/dev/test\n",
        "   * **PREGUNTA 2** ¿Para qué sirve cada partición?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1FwjLszpmLd"
      },
      "source": [
        "### Modelos\n",
        "\n",
        "**IMPORTANTE**:\n",
        "\n",
        "* El _modelo_ no es solo el clasificador que corremos sobre los features, sino también la manera en la que generamos los features!\n",
        "* Es fundamental entender qué hacen los modelos que vamos a probar, qué hiperparámetros tienen y qué hace cada uno -- si no entendemos los sistemas, es imposible saber por qué fallan y cómo mejorarlos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmRd0uZ-pmLd"
      },
      "outputs": [],
      "source": [
        "# Veamos cómo funciona BoW con CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "bow = CountVectorizer()\n",
        "\n",
        "textos = [\n",
        "    \"Qué rico que es el mate\",\n",
        "    \"el mate es muy... rico\",\n",
        "    \"el mate es rico?\",\n",
        "]\n",
        "# Aprende el vocabulario:\n",
        "bow.fit(textos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OJO: implícitamente hizo un preprocesamiento por default\n",
        "print(bow.vocabulary_)"
      ],
      "metadata": {
        "id": "bZQIM7qtT3fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJF3IonEpmLd"
      },
      "outputs": [],
      "source": [
        "# Para cada documento, contamos cuántas veces aparece cada palabra del vocabulario:\n",
        "print(bow.transform(textos).toarray()) # transformamos cada doc en un vector de dimension fija\n",
        "print(bow.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNeV2DyOpmLe"
      },
      "outputs": [],
      "source": [
        "# Como DataFrame:\n",
        "df_tmp = pd.DataFrame(bow.transform(textos).toarray(), columns=bow.get_feature_names_out())\n",
        "df_tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR7Ld1BipmLe"
      },
      "outputs": [],
      "source": [
        "# Y si lo aplicamos a textos que no estaban en el entrenamiento?\n",
        "textos_test = [\n",
        "    \"el mate es una bebida muy muy rica\",\n",
        "    \"Aguante Boca\",\n",
        "    \"Qué rico que es el té!!!\",\n",
        "]\n",
        "df_tmp = pd.DataFrame(bow.transform(textos_test).toarray(), columns=bow.get_feature_names_out())\n",
        "df_tmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXxtZriMpmLe"
      },
      "source": [
        "**IMPORTANTE**:\n",
        "\n",
        "* Tener control de lo que estamos haciendo, es decir, entender exactamente cómo estamos representando los documentos.\n",
        "    * **PREGUNTA 3** En el ejemplo anterior: ¿qué sucede con las palabras OOV? ¿Y con las palabras repetidas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Mnmh7ghpmLe"
      },
      "outputs": [],
      "source": [
        "# Corramos una version preliminar de un clasificador con BoW features:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=5_000)\n",
        "classifier = LogisticRegression(max_iter=1000, random_state=33)\n",
        "\n",
        "vectorizer.fit(df_train[\"text\"]) # Aprende el vocabulario\n",
        "X_train = vectorizer.transform(df_train[\"text\"]) # Transforma los textos en vectores\n",
        "# equivalente:\n",
        "# X_train = vectorizer.fit_transform(df_train[\"text\"])\n",
        "\n",
        "y_train = df_train[\"label\"]\n",
        "classifier.fit(X_train, y_train) # Entrena el clasificador\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNxuCq9CpmLf"
      },
      "outputs": [],
      "source": [
        "# Evaluamos en el conjunto de validación:\n",
        "X_val = vectorizer.transform(df_val[\"text\"])\n",
        "y_val = df_val[\"label\"]\n",
        "y_pred = classifier.predict(X_val)\n",
        "print(fbeta_score(y_val, y_pred, beta=1, average=\"macro\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREGUNTA 4** ¿Qué tipo de dato devuelve el método `.predict()`de este modelo? ¿Cómo se obtienen estos valores?"
      ],
      "metadata": {
        "id": "-Eh-HLeT58qV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mG2Bf68ppmLf"
      },
      "outputs": [],
      "source": [
        "# Con otros parametros:\n",
        "vectorizer = CountVectorizer(stop_words=\"english\", min_df=5)\n",
        "classifier = LogisticRegression(max_iter=1000, random_state=33)\n",
        "\n",
        "X_train = vectorizer.fit_transform(df_train[\"text\"])\n",
        "_ = classifier.fit(X_train, y_train)\n",
        "X_val = vectorizer.transform(df_val[\"text\"])\n",
        "y_pred = classifier.predict(X_val)\n",
        "print(fbeta_score(y_val, y_pred, beta=1, average=\"macro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp1fCAhMpmLg"
      },
      "outputs": [],
      "source": [
        "# Con TF-IDF:\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5_000)\n",
        "classifier = LogisticRegression(max_iter=1000, random_state=33)\n",
        "\n",
        "X_train = vectorizer.fit_transform(df_train[\"text\"])\n",
        "print(vectorizer.idf_) # idf de cada palabra\n",
        "print(vectorizer.get_feature_names_out()) # vocabulario"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREGUNTA 5**: ¿por qué podría ser TF-IDF mejor que el BoW simple?"
      ],
      "metadata": {
        "id": "2nHoFh936blo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsuCP0LipmLh"
      },
      "outputs": [],
      "source": [
        "_ = classifier.fit(X_train, y_train)\n",
        "X_val = vectorizer.transform(df_val[\"text\"])\n",
        "y_pred = classifier.predict(X_val)\n",
        "print(fbeta_score(y_val, y_pred, beta=1, average=\"macro\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI19lENdpmLh"
      },
      "source": [
        "**IMPORTANTE**:\n",
        "\n",
        "* ¿Cómo saber si el rendimiento es bueno? Dicho de otra manera: ¿estamos ganando algo con Machine Learning? --> para saberlo tenemos que comparar con un baseline!\n",
        "* El baseline puede ser un modelo ingenuo que siempre predice la clase mayoritaria, predecir aleatoriamente, o algo basado en reglas de negocio, expresiones regulares, etc -- depende del caso\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzpafrHopmLh"
      },
      "outputs": [],
      "source": [
        "# vamos usar un \"dummy classifier\" que predice segun las priors de entrenamiento\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "clf_dummy = DummyClassifier(strategy=\"prior\")\n",
        "_ = clf_dummy.fit(X_train, y_train)\n",
        "y_pred = clf_dummy.predict(X_val)\n",
        "print(fbeta_score(y_val, y_pred, beta=1, average=\"macro\"))\n",
        "\n",
        "# Con prediccion random?\n",
        "clf_dummy = DummyClassifier(strategy=\"uniform\")\n",
        "_ = clf_dummy.fit(X_train, y_train)\n",
        "y_pred = clf_dummy.predict(X_val)\n",
        "print(fbeta_score(y_val, y_pred, beta=1, average=\"macro\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREGUNTA 6** ¿qué quiere decir \"predecir según las priors de entrenamiento\" en el ejemplo de arriba?"
      ],
      "metadata": {
        "id": "N89NOXIO7e87"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svPPL9DupmLh"
      },
      "source": [
        "#### Selección de modelos\n",
        "\n",
        "**IMPORTANTE**:\n",
        "\n",
        "* En general un modelo no es UN modelo, sino un montón de configuraciones posibles. ¿Qué cosas podemos variar en este caso?\n",
        "  * stopwords (param `stop_words`)\n",
        "  * binary features (param `binary`)\n",
        "  * tokenización (param `tokenizer`, `nltk.tokenize.TweetTokenizer`, ...)\n",
        "  * usar ngramas como tokens (param `ngram_range`)\n",
        "  * preprocesamiento (param `preprocessor`: lowercase, stemming con `nltk.stem.SnowballStemmer`, eliminar palabras muy o poco frecuentes con `min_df` y `max_df`, etc.)\n",
        "  * propagación de negaciones (https://arxiv.org/ftp/arxiv/papers/1305/1305.6143.pdf section 5)\n",
        "  * features adicionales (e.g. conteo de palabras positivas/negativas, conteo de OOV words, ... usar la imaginacion!)\n",
        "  * Hiperparámetros del clasificador (e.g. regularizacion)\n",
        "  * **etc etc etc**\n",
        "\n",
        "* Antes de ponerse a correr código, definir qué pruebas quiero hacer y a qué tipo de resultado quiero llegar (un número? una tabla? un gráfico?)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREGUNTA 7** ¿qué quiere decir \"binary features\" en este contexto?"
      ],
      "metadata": {
        "id": "TeMdVlfG7vBj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4GdWPdLpmLi"
      },
      "outputs": [],
      "source": [
        "# para hacer seleccion de modelos de manera prolija podemos usar pipelines de sklearn\n",
        "# (tambien lo podemos programar a mano, claro!)\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Estos pasos se van a aplicar secuencialmente al input\n",
        "pipe = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(max_features=5_000)),\n",
        "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=33)),\n",
        "])\n",
        "\n",
        "_ = pipe.fit(df_train[\"text\"], y_train) # Ajusta todos los pasos\n",
        "y_pred = pipe.predict(df_val[\"text\"]) # Transforma y predice\n",
        "print(fbeta_score(y_val, y_pred, beta=1, average=\"macro\"))\n",
        "\n",
        "# Para usar CV en lugar de val set, podemos usar cross_val_score:\n",
        "# cross_val_score(pipe, X_train, y_train, cv=5, scoring='f1_macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyv3nbWFpmLi"
      },
      "outputs": [],
      "source": [
        "# A MODO ILUSTRATIVO, supongamos que nos interesa validar la eliminacion de\n",
        "# stopwords, el uso de bigramas, y el uso de tf-idf:\n",
        "\n",
        "# 1ro definimos un pipeline \"esqueleto\" con los pasos que queremos probar:\n",
        "pipe = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer()),\n",
        "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=33)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAZOziZQpmLi"
      },
      "outputs": [],
      "source": [
        "# 2do definimos el espacio de modelos que queremos explorar con una \"grilla\":\n",
        "param_grid = {\n",
        "    \"vectorizer\": [CountVectorizer(), TfidfVectorizer()],\n",
        "    \"vectorizer__stop_words\": [None, \"english\"],\n",
        "    \"vectorizer__ngram_range\": [(1, 1), (1, 2)],\n",
        "    # \"vectorizer__tokenizer\": [...],\n",
        "}\n",
        "# Podemos separar pruebas usando una lista de diccionarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiPMJvs2pmLi"
      },
      "outputs": [],
      "source": [
        "# 3ro entrenamos todas las configuraciones posibles en train y evaluamos cada una en val:\n",
        "# (usamos PredefinedSplit para que el conjunto de validacion sea siempre el mismo en GridSearchCV)\n",
        "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
        "\n",
        "X = pd.concat([df_train, df_val]).reset_index(drop=True)[\"text\"]\n",
        "y = pd.concat([df_train, df_val]).reset_index(drop=True)[\"label\"]\n",
        "val_fold = [-1]*len(df_train) + [0]*len(df_val)\n",
        "ps = PredefinedSplit(val_fold)\n",
        "grid_search = GridSearchCV(\n",
        "    pipe, param_grid, cv=ps, scoring=\"f1_macro\", refit=False, verbose=10)\n",
        "\n",
        "# Si hay demasiadas configuraciones posibes, podemos usar RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxTcNM82pmLj"
      },
      "outputs": [],
      "source": [
        "_ = grid_search.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREGUNTA 8** ¿por qué hay 8 lineas en el print anterior?"
      ],
      "metadata": {
        "id": "i_6yxYVU8t0o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1dLnbKJpmLt"
      },
      "outputs": [],
      "source": [
        "df_results = pd.DataFrame(grid_search.cv_results_)\n",
        "df_results.sort_values(\"rank_test_score\").head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRmND-tspmLt"
      },
      "outputs": [],
      "source": [
        "df_results.sort_values(\"rank_test_score\").tail(1)\n",
        "# El tuneo de HPs puede ser fundamental!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlbPo649pmLt"
      },
      "source": [
        "### Análisis de resultados\n",
        "\n",
        "**IMPORTANTE**:\n",
        "\n",
        "* Muchas veces no solo importa el rendimiento del modelo, sino también entender qué está haciendo. Por ejemplo:\n",
        "  * Feature importance: A qué features le da importancia el modelo? Tiene sentido?\n",
        "  * Análisis de errores: en qué casos falla? qué tipos de errores comete? Puede ser muy útil primero correr un modelo sencillo y analizar los errores que comete, para tener una idea de por dónde conviene seguir trabajando.\n",
        "  * Usar la imaginación!\n",
        "\n",
        "* A la hora de analizar y presentar métricas, poner el foco en las que nos importan -- no mostrar todos los números porque sí"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3y2aF6WBpmLt"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import clone\n",
        "\n",
        "best_pipe = clone(pipe)\n",
        "best_pipe = best_pipe.set_params(**grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oWhVQblpmLt"
      },
      "outputs": [],
      "source": [
        "best_pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5nUBIhmpmLu"
      },
      "outputs": [],
      "source": [
        "# análisis de metricas\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "_ = best_pipe.fit(df_train[\"text\"], df_train[\"label\"])\n",
        "y_pred = best_pipe.predict(df_val[\"text\"])\n",
        "\n",
        "print(classification_report(df_val[\"label\"], y_pred))\n",
        "\n",
        "cm = confusion_matrix(df_val[\"label\"], y_pred)\n",
        "plt.figure(figsize=(3,2))\n",
        "sns.heatmap(\n",
        "    cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "    xticklabels=best_pipe.classes_, yticklabels=best_pipe.classes_)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREGUNTA 9**: ¿por qué cada clase tiene un valor de f-score distinto? ¿qué es el \"macro avg\"?"
      ],
      "metadata": {
        "id": "M_WFMBbA9Abl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAymAmK5pmLu"
      },
      "outputs": [],
      "source": [
        "# analisis de errores:\n",
        "df_val[\"proba_pred\"] = best_pipe.predict_proba(df_val[\"text\"]).max(axis=1)\n",
        "df_val[\"pred\"] = y_pred\n",
        "df_val[\"correct\"] = df_val[\"label\"] == df_val[\"pred\"]\n",
        "\n",
        "# Top 5 errores:\n",
        "df_val[~df_val[\"correct\"]].sort_values(\"proba_pred\", ascending=False).head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0K9jsSbpmLu"
      },
      "outputs": [],
      "source": [
        "# feature importance\n",
        "features = best_pipe.named_steps[\"vectorizer\"].get_feature_names_out()\n",
        "classes = best_pipe.classes_\n",
        "weights = best_pipe.named_steps[\"classifier\"].coef_ # shape (n_classes, n_features)\n",
        "\n",
        "for i, label in enumerate(classes):\n",
        "    feat_importance = pd.Series(weights[i], index=features).sort_values(ascending=False)\n",
        "    fig, ax = plt.subplots(figsize=(10, 3))\n",
        "    ax.barh(feat_importance.index[:10], feat_importance.values[:10], color=\"darkgreen\")\n",
        "    ax.barh(feat_importance.index[-10:], feat_importance.values[-10:], color=\"crimson\")\n",
        "    ax.invert_yaxis()\n",
        "    plt.title(f\"class={label}\")\n",
        "    plt.ylabel(\"Feature importance\")\n",
        "    plt.yticks(size=9)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREGUNTA 10** ¿Qué está almacenado en el objeto `weights`? ¿Qué significa que sean negativos o positivos?\n"
      ],
      "metadata": {
        "id": "rz8MWNq79Ym7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NzuszgypmLv"
      },
      "outputs": [],
      "source": [
        "# Evaluacion en test set\n",
        "\n",
        "# cuando evaluamos en test podemos entrenar con train+val\n",
        "X = pd.concat([df_train, df_val]).reset_index(drop=True)[\"text\"]\n",
        "y = pd.concat([df_train, df_val]).reset_index(drop=True)[\"label\"]\n",
        "_ = best_pipe.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREGUNTA 11**: ¿por qué no hicimos la búsqueda de hiperparámetros en el test set?"
      ],
      "metadata": {
        "id": "yWxAGYG79hfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = best_pipe.predict(df_test[\"text\"])\n",
        "\n",
        "print(classification_report(df_test[\"label\"], y_pred_test))\n",
        "\n",
        "cm = confusion_matrix(df_test[\"label\"], y_pred_test)\n",
        "plt.figure(figsize=(3,2))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=best_pipe.classes_, yticklabels=best_pipe.classes_)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kNkdQT4XZri8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26SeFP6rpmLv"
      },
      "source": [
        "### Bonus track\n",
        "\n",
        "¿Cómo agregar otros features?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls-tGFCYpmLv"
      },
      "outputs": [],
      "source": [
        "# Por ejemplo:\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import FeatureUnion, FunctionTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
        "\n",
        "X = pd.concat([df_train, df_val]).reset_index(drop=True)[[\"text\"]]\n",
        "\n",
        "X[\"ft_log_n_words\"] = X[\"text\"].apply(lambda x: np.log10(len(x.split())))\n",
        "X[\"ft_log_n_users\"] = np.log10(np.random.randint(1, 1_000, size=len(X))) # por ejemplo\n",
        "X[\"ft_has_exclamation\"] = X[\"text\"].str.contains(\"!\")\n",
        "# OJO: acá podemos aplicar transformaciones a todos los datos juntos porque\n",
        "# son transformaciones que no dependen de la particion train/val/test. Si no\n",
        "# es así, podemos hacerlo en el pipeline para que no haya \"data leakage\".\n",
        "\n",
        "# Esto puede estar un poco desactualizado pero anda,\n",
        "# con versiones nuevas usar ColumnTransformer\n",
        "class FeatSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, variables):\n",
        "        self.variables = variables\n",
        "    def fit(self, df, y=None):\n",
        "        return self\n",
        "    def transform(self, df):\n",
        "        return df[self.variables]\n",
        "    def get_feature_names(self):\n",
        "        return self.variables\n",
        "\n",
        "vectorizer = Pipeline([\n",
        "    ('selector', FeatSelector(variables='text')),\n",
        "    ('feat_extractor', TfidfVectorizer(min_df=10, max_features=1000, binary=True)),\n",
        "    ('to_dense', FunctionTransformer(lambda x: x.toarray(), accept_sparse=True)),\n",
        "])\n",
        "other_features = ['ft_log_n_words', 'ft_log_n_users', 'ft_has_exclamation']\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('features', FeatureUnion([\n",
        "        ('text', vectorizer),\n",
        "        ('others', FeatSelector(variables=other_features)), # con \"passthrough\" podemos excluir este paso\n",
        "    ])),\n",
        "    ('scaler', MinMaxScaler()), # Fundamental si usamos regularizacion\n",
        "    ('clf', LogisticRegression(max_iter=1000, random_state=33)),\n",
        "])\n",
        "\n",
        "X_train = X.loc[df_train.index]\n",
        "y_train = df_train[\"label\"]\n",
        "X_val = X.loc[df_val.index]\n",
        "\n",
        "_ = pipe.fit(X_train, y_train)\n",
        "y_pred = pipe.predict(X_val)\n",
        "print(fbeta_score(df_val[\"label\"], y_pred, beta=1, average=\"macro\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StUP2NECpmLv"
      },
      "source": [
        "---------------------------------------"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}