{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Normalización.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO5dW7dNP+V9a5xCyth930K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LCaravaggio/NLP/blob/main/02_b%C3%A1sicas/Normalizaci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Tokenization"
      ],
      "metadata": {
        "id": "OTw0FHtDQhij"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYQVNnamPouQ",
        "outputId": "d315b943-8aa9-4746-f55e-5b84abbe88bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.word_tokenize(\"Hola, mi nombre es Leonardo\", language=\"spanish\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87jVjiKRQKG5",
        "outputId": "ae973acf-e28c-4fd1-a430-501e7ec5ca51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hola', ',', 'mi', 'nombre', 'es', 'Leonardo']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tolenización de oraciones"
      ],
      "metadata": {
        "id": "vOboug0ZQ-q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.sent_tokenize(\"Hola, mi nombre es Leonardo. Quiero mostrarles como separar un texto en oraciones. Con NLTK, es muy fácil\", language=\"spanish\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiIIseW7RGEM",
        "outputId": "9f05e8e8-ed92-4533-b07f-5974a70f0d5e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hola, mi nombre es Leonardo.',\n",
              " 'Quiero mostrarles como separar un texto en oraciones.',\n",
              " 'Con NLTK, es muy fácil']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization\n"
      ],
      "metadata": {
        "id": "j59onz66RUTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlz6w4MncMG7",
        "outputId": "86fd4d27-640e-4457-a666-ccea6972177d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words=(\"corpora\", \"rocks\")\n",
        "for word in words: \n",
        "  print(lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3GkdY61RVpw",
        "outputId": "900db0d4-25c5-4faa-970e-ee4cf25cf8a5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "corpus\n",
            "rock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization en español"
      ],
      "metadata": {
        "id": "AXY4Dy2CSJqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "BD1790JvZwE0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!python -m spacy download es_core_news_md"
      ],
      "metadata": {
        "id": "QyEHNjGoZunY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"es_core_news_md\")"
      ],
      "metadata": {
        "id": "LIjJgK0IZt4u"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u\"correr corre correría correrá\")\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.dep_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVI90pWASKkX",
        "outputId": "760abeca-24d7-4232-ff30-485fba289bf2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correr correr csubj\n",
            "corre correr ccomp\n",
            "correría correr compound\n",
            "correrá correr ROOT\n"
          ]
        }
      ]
    }
  ]
}